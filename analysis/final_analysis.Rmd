---
title: "R Notebook"
output: html_notebook
---

# General imports

```{r}
library(jsonlite)
library(tidyverse)
library(ggthemes)
library(lme4)
library(lmerTest)
library(tidyboot)
```

# Experiment 1

```{r}
exp1_messages <- read_csv('../data/final/experiment1/chatMessage/messagesFromMongo.csv') %>%
  mutate(critical = ifelse(critical == 'True', 1, 0)) %>%
  rename(messageTime = serverTime) %>%
  filter(sender == 'director') %>%
  group_by(gameid, trialNum, instructionNum, attemptNum, critical, condition, objectSet, targetObject) %>%
  summarize(text = paste0(contents, collapse = ' '),
            typingRT = sum(typingRT)) %>%   # Concatenate multiple utterance on same trial
  mutate(numRawWords = str_count(text, "\\S+")) 

## Have to fix attemptNum bug (got recorded incorrectly)
exp1_drops <- read_csv('../data/final/experiment1/drop/dropsFromMongo.csv') %>%
  mutate(critical = ifelse(critical == 'True', 1, 0),
         correct = ifelse(correct == 'correct', 1, 0),
         instructionNum = ifelse(correct == 0, instructionNum + 1, instructionNum)) %>%
  group_by(gameid, instructionNum, trialNum) %>%
  mutate(attemptNum = ifelse(attemptNum == 0, max(attemptNum), attemptNum - 1)) %>%
  rename(dropTime = serverTime) %>%
  select(-X1, -eventType)
```

```{r}
exp1_subjInfo <- read_csv('../data/final/experiment1/turk/subjInfo.csv')
incompleteIDs <- unique((exp1_messages %>% 
                           group_by(gameid, trialNum, instructionNum) %>% 
                           summarize(id = row_number()) %>% 
                           group_by(gameid) %>% 
                           tally() %>% 
                           filter(n != 32))$gameid)

confused <- unique((exp1_subjInfo %>% filter(understandsInstructions != 'yes'))$gameid)
nonNative <- unique((exp1_subjInfo %>% filter(nativeEnglish != 'yes'))$gameid)

nonCriticalMistakes <- unique((exp1_drops %>%
  # only look at mistakes on noncritical (filler) items
  filter(critical != 1) %>%
  # don't want to double-count people for messing the same thing up multiple times
  filter(attemptNum == 1) %>% 
  group_by(gameid, correct) %>%
  tally() %>%
  # implement exclusion criteria of errors on >~10% of non-critical trials
  filter(n > 1))$gameid)

exp1_badGames <- c(incompleteIDs, nonNative, confused, nonCriticalMistakes)

exp1_d <- exp1_messages %>%
  left_join(exp1_drops) %>% #, by = c('gameid', 'trialNum', 'instructionNum', 'trialType', 
                      #         'targetObject', 'critical', 'condition', 'attemptNum')) %>%
  filter(!(gameid %in% exp1_badGames))
```

## Descriptive stats

How many recruited, how many excluded, for what reasons, etc?

```{r}
paste0('recruited ', length(exp1_subjInfo$gameid))
paste0('total games ', length(unique(exp1_drops$gameid)))
paste0('incomplete ', length(incompleteIDs))
paste0('too many mistakes ', length(setdiff(union(confused, nonCriticalMistakes), incompleteIDs)))
paste0('non-native english ', length(setdiff(nonNative, union(confused, union(nonCriticalMistakes, incompleteIDs)))))
paste0('final sample ', length(unique(exp1_d$gameid)))
```

Happened to get slightly more people in scripted condition

```{r}
exp1_d %>% 
  group_by(gameid, condition) %>% 
  tally() %>% 
  group_by(condition) %>% 
  summarize(numInCondition = length(n))
```

## Listener Analyses

First, look at error rates

```{r}
critTrials <- exp1_d %>% 
  filter(attemptNum == 0) %>%
  filter(critical == 1) %>%
  filter(trialType == 'exp') 

critTrials %>%
  group_by(gameid, condition) %>%
  summarize(pctCriticalError = 1 - mean(correct)) %>%
  ggplot(aes(x = pctCriticalError, fill = condition)) +
    #geom_density(aes(y = ..density../sum(..density..)), alpha = 0.5, adjust = 1.25)
    geom_histogram(aes(y = ..count../sum(..count..)), alpha = 0.5, position = 'dodge', binwidth = 0.125)  +
    facet_grid(condition ~ .) +
    theme_few()

ggsave('~/Downloads/criticalErrors.pdf')
```

```{r}
errorTable <- critTrials %>%
  group_by(gameid, condition) %>%
  summarize(numErrors = 4 - sum(correct),
            numPossible = length(correct),
         atLeastOnce = sum(correct) < 4,
         atLeastTwice = sum(correct) < 3,
          atLeastThree = sum(correct) < 2,
         pctErrors = 1 - mean(correct)) %>%
  group_by(condition) %>%
  summarize(pctAtLeastOnce = mean(atLeastOnce),
            pctAtLeastTwice = mean(atLeastTwice),
            pctAtLeastThree = mean(atLeastThree),
            avgPctErrors = mean(pctErrors),
            totalNumErrors = sum(numErrors),
            totalPossible = sum(numPossible))
errorTable
```

### Statistical tests of error reduction

```{r}
prop.test(errorTable$totalNumErrors, errorTable$totalPossible)
```

### Control for item-level error rates...

```{r}
summary(glmer(correct ~ condition + (1|gameid) + (1+condition | objectSet), family = 'binomial', 
              data = critTrials))
```

## Error heterogeneity across items...

```{r}
diffs <- critTrials %>% 
  mutate(error = 1 - correct) %>%
  group_by(objectSet, condition, targetObject) %>%
  summarize(pctErrors = mean(error)) %>%
  spread(condition, pctErrors) %>%
  mutate(errorReduction = scripted - unscripted) %>%
  gather(condition, pctErrors, scripted, unscripted) 

critTrials %>% 
  left_join(diffs) %>%
  mutate(error = 1 - correct) %>%
  group_by(objectSet, condition, targetObject, errorReduction) %>%
  tidyboot_mean(column = error) %>%
  ggplot(aes(x = reorder(targetObject, -errorReduction), y = empirical_stat, color = condition, group = condition)) +
    geom_point() +
    geom_line(stat = 'identity', position = 'dodge') +
    geom_errorbar(aes(ymax = ci_upper, ymin = ci_lower), width = 0) +
    theme_few() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    ggtitle('error heterogeneity across item') +
    xlab('critical item') +
    ylab('% error in condition')

ggsave('~/Downloads/itemHeterogeneity.pdf')
```

```{r}
exp1_d %>% 
  filter(attemptNum == 0) %>%
  filter(correct == 1) %>%
  filter(critical == 1) %>% 
  ungroup() %>%
  filter(responseTime < median(responseTime, na.rm = T) +  3* sd(responseTime)) %>%
  group_by(trialType, condition) %>%
  mutate(m = median(responseTime)) %>%
  ggplot(aes(x = responseTime)) +
    geom_histogram() +
    geom_vline(aes(xintercept = m))+
    facet_wrap(trialType ~ condition) +
    scale_x_log10() +
    theme_few() 
```

```{r}
summary(lmer(log(responseTime) ~ trialType * condition + (1 | gameid),
     data = exp1_d %>% 
        filter(attemptNum == 0) %>%
        filter(correct == 1) %>%
        filter(critical == 1) %>% 
        ungroup() %>%
        filter(responseTime < median(responseTime, na.rm = T) +  3* sd(responseTime))))
```

## Mouse-tracking 

Even on critical trials where they didn't make errors, how often did they 'consider' the distractor (i.e. hover over the distractor cell)

```{r}
d.onDistractor <- exp1_d %>% 
  left_join(read_csv('../data/final/experiment1/mouseOverDistractor/distractorMouseFromMongo.csv') %>% 
              mutate(critical = ifelse(critical == 'True', 1, 0))
            ) %>%
  select(-serverTime, -X1) %>%
  filter(attemptNum == 0) %>%
  filter(correct == 1) %>%
  filter(critical == 1) %>%
  group_by(gameid, trialNum) %>%
  mutate(toggle = floor((row_number() - 1) / 2)) %>%
  mutate(onOff = ifelse(is.na(onOff), 'off', onOff)) %>%
  spread(onOff, timeElapsed) %>%
  mutate(diff = ifelse(is.na(off), 0, off - on)) %>%
  group_by(gameid,condition,objectSet, trialType) %>%
  summarize(totalAmtTimeOnDistractor = sum(diff)) %>%
  mutate(hovered = totalAmtTimeOnDistractor > 0) %>%
  ungroup() 

dodge <- position_dodge(width=0.9)
d.onDistractor %>%
  group_by(condition, trialType) %>%
  tidyboot_mean(column = hovered) %>%
  ggplot(aes(x = condition, y=empirical_stat, fill = trialType)) +
    geom_bar(stat = 'identity', position = dodge) +
    geom_errorbar(aes(ymax = ci_upper, ymin = ci_lower), width = 0, position = dodge) +
    theme_few() +
    ylab('% trials hovering over distractor') +
    theme(aspect.ratio = 0.5)

ggsave('~/Downloads/hoverOverDistractor.pdf')
```

```{r}
summary(glmer(hovered ~ trialType * condition + (1 + trialType|gameid) + (1 |objectSet), data = d.onDistractor, family = 'binomial'))
```


Note: because I stopped recording from the mouse as soon as someone starts dragging, it's technically possible for them to hover over the distractor object, click and start to drag it, but then drop it in place and go over to the target object. So they get it 'correct' even though it looks like their mouse never gets close... 

Note: a couple researcher degrees of freedom here: 
* do we take the time from 'object reveal' or from first mouse move (i.e. subtract off the first time recorded NOT in target or distractor)? 
* do we restrict to only 'correct' trials (i.e. to make an argument like "even when they got it right, they were still distracted") or include everything?
* how big a radius around the target center should we consider a 'mouse-fixation' (obviously needs to be close enough to move it, but objects were different sizes...)

```{r}
# Touch people?
touch <- c('0095-03bb67a7-ae89-402d-9f7f-c5898784e63f', '0093-b4e1ce5c-2e5c-462a-bfed-87fa81611139')
targetRadius = 175
d.mouse <- exp1_d %>% ungroup() %>%
  left_join(read_csv('../data/final/experiment1/updateMouse/mouseFromMongo.csv') %>%
                  mutate(critical = ifelse(critical == 'True', 1, 0))
  ) %>%
  filter(!(gameid %in% touch)) %>%
  filter(critical == 1) %>% filter(attemptNum == 0) %>% filter(correct == 1) %>%
  select(-critical, -attemptNum, -eventType, -iterationName) %>%
  mutate(distractorDistance = as.numeric(distractorDistance)) %>%
  group_by(condition, trialType, gameid, objectSet, onTarget = targetDistance < targetRadius) %>%
  summarize(firstTime = first(timeFromReveal), 
            lastTime = last(timeFromReveal)) %>%
  group_by(condition, trialType, gameid, objectSet) %>%
  summarize(initMouseMove = min(firstTime), 
            initTargetHover = max(firstTime) - initMouseMove, 
            finalTargetHover = max(lastTime) - initMouseMove) %>%
  select(-initMouseMove) %>%
  gather(metric, value, initTargetHover, finalTargetHover) %>%
  #spread(onTarget, value) %>%
  #mutate(timeFromFirstMouseMove = `TRUE` - `FALSE`) %>%
  #ungroup() %>%
  #filter(firstTime < mean(firstTime, na.rm = T) + 3 * sd(firstTime, na.rm = T)) %>%
  group_by(condition, trialType, metric) %>%
  tidyboot_mean(column = value)

d.mouse
ggplot(d.mouse, aes(x = trialType, y = empirical_stat, fill = metric)) +
  geom_bar(stat= 'identity', position = dodge) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), position = dodge, width = 0) +
  facet_wrap(~ condition) +
  theme_few()
```

# Experiment 2

## Import turk survey data 

```{r}
exp2_subjInfo <- read_csv('../data/final/experiment2/planned_sample/turk/subjInfo.csv')
```

## Import message data

```{r}
d_annotated <- read_csv('../data/final/experiment2/planned_sample/chatMessage/messages_with_annotations.csv') 

# nonNativeSpeakerIDs <- unique((tangramSubjInfo %>% filter(nativeEnglish != "yes"))$gameid)
incompleteIDs <- unique((d_annotated %>% group_by(gameid) %>% 
                           filter(length(unique(trialNum)) != 24))$gameid)
confused <- unique((exp2_subjInfo %>% filter(understandsInstructions != 'yes'))$gameid)

# Some speakers relied on location in grid (TODO: WHAT ABOUT 'BELOW' PEOPLE?)
location_abusers <- c('8219-bb7861c1-43f4-480c-906b-8441c583c0ab', 
                      '7726-3d4a266f-e56d-4afb-9a79-b40deb690a76', 
                      '5684-f09de856-4d64-423c-b342-b30e7325eb0e', 
                      '7600-346d56b5-bd76-406f-befb-6b47e07d5916')
# Some speakers played this weird taboo game where they gave riddles 
tabooers <- c('2929-d218f724-b45e-416b-af44-5cab5658bad9', #(opposite of white... primary color...)
              '7600-346d56b5-bd76-406f-befb-6b47e07d5916', # MERRY GO ROUND
              '3462-7e95c955-4087-4eb9-bbc8-05338f9a5e4b') # CAN YOU SEE???
badGames <- c(incompleteIDs, pureLocation, confused)

d <- d_annotated %>%
  mutate(numFeatures = colorMention + shapeMention + textureMention) %>%
  filter(!(gameid %in% badGames))
```

## Check basic (no-hidden) pragmatic effect

```{r}
basic.d <- d %>%
  filter(hidden == 'no') %>%
  group_by(gameid, context) %>%
  summarize(m = mean(numRawWords)) %>%
  spread(context, m) %>%
  mutate(diff = close- far,
         ratio = log(close / far))
 
ggplot(basic.d, aes(x = far, y = close)) +
    geom_point() +
    theme_bw() +
    geom_abline(intercept = 0, slope = 1) +
    ylim(1,12) +
    xlim(1,12) +
    theme(aspect.ratio = 1)
```

Aggregated to difference scores:

```{r}
ggplot(basic.d, aes(x = ratio)) +
    geom_histogram(binwidth = 0.25) +
    theme_bw() +
    geom_vline(xintercept = 0) +
    # ylim(1,12) +
    xlim(-4,4) +
    theme(aspect.ratio = 1)

t.test(basic.d$ratio)
```

## Message length collapsing across all subjects

```{r}
dodge <- position_dodge(width=0.9)

d %>%
  group_by(context, hidden) %>%
  tidyboot_mean(column = numRawWords) %>%
  ggplot(aes(x = context, y = empirical_stat, fill = hidden)) +
    geom_bar(stat = 'identity', position = dodge) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), position = dodge, width = 0) +
    theme_few() +
    ylab('mean # words') +
    theme(aspect.ratio = .5) +
    scale_fill_colorblind()

ggsave('~/Downloads/aggregated_means.pdf', width = 4, height = 2)
```

## Scatter to look at within-subj effects

Some people used exactly the same number of words on every trial...

```{r}
hidden.d %>% 
  filter(context == 'far') %>% 
  mutate(group = case_when(diff < -0 ~ 'anti',
                           diff > 0 ~ 'pro',
                           TRUE ~ 'all_the_things')) %>%
  group_by(group) %>% tally()

all_the_things_ers <- (hidden.d %>% filter(context =='far') %>% filter(diff == 0))$gameid
```

```{r}
hidden.d <- d %>%
  group_by(gameid, context, hidden) %>%
  summarize(m = mean(numRawWords)) %>%
  spread(hidden, m) %>%
  mutate(diff = yes- no,
         ratio = log(yes/no)) 

ggplot(hidden.d, aes(x = no, y = yes)) +
    geom_point() +
    facet_wrap(~ context) +
    theme_bw() +
    geom_abline(intercept = 0, slope = 1) +
    ylim(1,15) +
    ylab('# words (with occlusions)') +
    xlab('# words (without occlusions)') +
    ggtitle('Within-pair comparisons of reference w/ and w/out occlusion') +
    xlim(1,15) +
    theme(aspect.ratio = 1)

ggsave('~/Downloads/scatter.pdf')
```

Histogram

```{r}
ggplot(hidden.d %>% filter(!(gameid %in% all_the_things_ers)) %>% group_by(context) %>% mutate(m = mean(diff)), aes(x = diff)) +
    geom_histogram(binwidth = 0.33) +
    theme_bw() +
    geom_vline(xintercept = 0, linetype = 2) +
    geom_vline(aes(xintercept = m), color = 'red') +
    facet_wrap(~ context) +
    # ylim(1,12) +
    xlim(-6,6) +
    theme(aspect.ratio = 1)

ggsave("~/Downloads/histograms.pdf")
```

```{r}
hidden.d %>%
  group_by(context) %>%
  summarize(m = mean(diff), se = sd(diff)/sqrt(length(diff))) %>%
  ggplot(aes(x = context, y = m)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = m - se, ymax = m + se), width = 0) +
    theme_few() +
    ylim(-3, 3) +
    ylab('# words (occlusions - no occlusions)')
  
```

# Stats

Simple effect of hidden-ness in 'far' contexts 

```{r}
summary(lmer(numRawWords ~ hidden + (1 + hidden | gameid), 
             data = d %>% 
               filter(context == 'far') %>%
               filter(!(gameid %in% all_the_things_ers))
               ))
t.test(numRawWords ~ hidden, data = d %>% filter(context == 'far') , var.equal = FALSE)
```

interaction-y way

```{r}
summary(lmer(numRawWords ~ context * hidden + (1 + context * hidden | gameid), data = d %>% filter(!(gameid %in% all_the_things_ers))))
```

helmert coding way (one way of slicing)

```{r}
d.regression <- d %>% 
  unite(condition, context, hidden) %>%
  ungroup() %>%
  mutate(condition = ordered(condition, levels = c('far_no', 'close_no', 'far_yes', 'close_yes')))
contrasts(d.regression$condition) <- contr.helmert(4)
summary(lmer(numRawWords ~ condition + (1 + condition | gameid), data = d.regression))
```

## Use feature data instead

```{r}
d %>% 
  group_by(context, occlusions) %>% 
  summarize(color = mean(colorMention), shape = mean(shapeMention), texture = mean(textureMention))
```

Histograms of number of features mentioned in each condition

```{r}
ggplot(d, aes(x = numFeatures)) +
  geom_histogram(binwidth = 1) +
  facet_grid(context ~ occlusions) +
  theme_few()
```

```{r}
d %>% group_by(context, occlusions) %>% 
  mutate(numTrials = length(text)) %>% 
  group_by(context, occlusions, colorMention, textureMention) %>% 
  summarize(n = length(text)/mean(numTrials)) %>%
  ggplot(aes(x = colorMention, y = textureMention, fill = n)) +
    geom_bin2d(stat = 'identity') +
    stat_bin2d(geom = "text", aes(label = round(n, 2))) +
    scale_fill_gradient(low = "white", high = "red") +
    facet_grid(occlusions ~ context) +
    theme_few()
```

Note: Random intercept doesn't converge (less variance in these numbers...)

```{r}
summary(lmer(numFeatures ~ context * occlusions + (1 + context + occlusions | gameid), data = d))
```

```{r}
summary(glmer(colorMention ~ occlusions + (1 + occlusions | gameid), family = 'binomial', data = d))
```

```{r}
summary(glmer(textureMention ~ occlusions + (1 + occlusions | gameid), family = 'binomial', data = d))
```

```{r}
d %>% 
  group_by(context, occlusions) %>% 
  summarize(numFeatures = mean(numFeatures))
```

```{r}
d.booted <- d %>% 
  gather(feature, mentioned, shapeMention, colorMention, textureMention) %>%
  group_by(context, hidden, feature) %>% 
  tidyboot_mean(column = mentioned) 

ggplot(d.booted, aes(x = context, y = empirical_stat, fill = hidden)) + 
  geom_bar(stat = 'identity', position = dodge) +
  geom_errorbar(aes(ymax = ci_upper, ymin = ci_lower), position = dodge, width = 0) +
  facet_wrap(~ feature) + 
  theme_few() +
  theme(aspect.ratio = 1) + 
  ylab('% utterances with feature') +
  scale_fill_colorblind()

ggsave('~/Downloads/by-feature-analysis.pdf')
```
