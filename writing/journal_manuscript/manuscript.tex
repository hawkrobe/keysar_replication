%% Documentclass:
\documentclass[manuscript]{stjour}

%% Or,

%% Manuscript, for double spaced, larger fonts
% \documentclass[manuscript]{stjour}
%% Only needed if you use `manuscript' option
\journalname{Open Mind}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% For production only, not authors:
%%\documentclass[OpenMind,finalfonts]{stjour}

%%%%%%%%%%% Please supply information %%%%%%%%%%%%%%%%%%%%%%%%%

%% For Open Mind:
%% Supplementary Materials:
\supplementslinks{dx.doi.org/10.1098/rsif.2013.0969}

%% If no conflicts, this command doesn't need to be used
%% \conflictsofinterest{}

%%%%%%%%%%% to be supplied by MIT Press, only %%%%%%%%%%%%%%%%%

\citation{Niyogi, R. K., Breton, Y.-A., Solomon,
R. B., Conover, K.,\\ Shizgal, P., Dayan, P. (2015).\\ 
Optimal indolence: a normative microscopic approach to work and leisure. Open Mind 1(1):
1âˆ’12.}

\received{XXX}
\accepted{XXX}
\published{XXX}

%% DOI address:
\setdoi{10.1098/rsif.2013.0969}

%%%%%%%% End MIT Press commands %%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% author definitions should be placed here:

%% example definition
\def\taupav{\tau_{\mathrm{Pav}}}
\usepackage{todonotes}
\begin{document}

\title{The pragmatics of perspective-taking}
\subtitle{Gricean expectations account for apparent limits on theory of mind use}

%% If shortened title for running head is needed so that the article title can fit
%%   in the running head, use [] argument, ie,
%%
%%   \title[Shortened Title for Running Head]{Title of Article}
%%   \subtitle{Subtitle Here}

%% Since we use \affil{} in the argument of the \author command, we
%% need to supply another version of the author names, without \affil{}
%% to be used for running heads:

\author[Hawkins, Gweon, Goodman]
{Robert Hawkins\affil{1}, Hyowon Gweon\affil{1}, Noah Goodman\thanks{asdf}\affil{1}}

\affiliation{1}{Department of Psychology, Stanford University, Stanford, CA, US}

%ie.
%\affiliation{1}{Gatsby Computational Neuroscience Unit, University
%College London, London, United Kingdom} 

%\affiliation{2}{Another Department, Institution, City, Country}

%ie
%\affiliation{2}{Center for Studies in
%Behavioral Neurobiology, Concordia University, Montreal, Quebec,
%Canada}

\correspondingauthor{Robert Hawkins}{rxdh@stanford.edu}

% ie,
%\correspondingauthor{Ritwik K. Niyogi}{ritwik.niyogi@gatsby.ucl.ac.uk}

\keywords{theory of mind, pragmatics, interaction, communication, social cognition, replication}

%ie
%\keywords{work, leisure, normative, microscopic,  reinforcement learning, economics}

\begin{abstract}
%To communicate successfully, speakers must flexibly adapt %the specificity of 
%their utterances to the demands of the current context. When they are unsure exactly which objects are in view of their partner, for example, they may provide additional disambiguating information when referring to a particular object: saying "cassette tape" instead of the potentially ambiguous ``tape."
Recent debates over adult theory of mind use have hinged on natural-language communication tasks with knowledge asymmetries, but have largely neglected the nuanced pragmatics of these tasks.  In particular, using occluded objects to create perspective asymmetries may have unexpected side effects under pragmatic reasoning. Cooperative speakers ought to flexibly adjust their utterances to be more informative uncertainty about what is in the listener's field of view. In a direct replication, we show that scripted confederates violate these expectations by using less informative labels than unscripted directors naturally use. In a follow-up experiment, we directly manipulate whether objects are hidden to test the pragmatic account of speaker informativity in uncertain environments. Hence, apparent failures of visual perspective-taking may in fact be successes for sophisticated theory of mind use in context. Language is well-tuned to deal with knowledge mismatch, and perspective neglect is just part of that.
%Recent theories of language use as recursive social reasoning remain in tension with evidence that adult listeners apparently fail to take their partner's perspective in communication. To reconcile these points of view, we use a computational model of communication under uncertainty to analyze the pragmatic demands of a common theory of mind test.  Through a minimal pair of replications comparing scripted vs. unscripted speakers, we show that scripted confederates used in previous studies are \emph{uncooperative}: they are less informative than what a speaker would actually produce in that situation, thus violating the listener's rational social expectations. This ironically shows that apparent failures of theory of mind are in fact attributable to sophisticated expectations about speaker behavior---that is, to theory of mind. 
\end{abstract}

\section{Introduction}\label{introduction}

%%% Characterize the computational approach to theory of mind we plan to take
%%% Point out a gaping hole that could benefit from this approach
%Our success as a cooperative species depends upon our ability to make sense of other agents. 
%One solution is to maintain an internal predictive model of other agents: how unobservable beliefs and desires give rise to observable actions. 
%Such a model allows us to make inferences about a social partner's likely internal state given their past behavior and form sophisticated expectations about their future behavior. 
%This theoretical approach to social cognition, where theory of mind reasoning \cite{PremackWoodruff78_ChimpanzeeToM, GopnikWellman92_TheoryTheory, WellmanCrossWatson01_ToMMetaAnalysis, SetohScottBaillargeon16_FalseBelief, ScottBaillargeon17_EarlyToM} is grounded in an explicit computational model of how other minds work, has 
% The approach has been useful for understanding a number of experimental phenomena in both adults and children \cite{KileyHamlinEtAl13_MentalisticCoreSocial, PantelisEtAl14_IntentionInference}. 
%Yet our current understanding of theory of mind use in \emph{communication} remains limited. 

Our ability to successfully communicate and coordinate with social partners relies on some degree of contextual flexibility in production and interpretation. When trying to refer to a particular dog at a busy dog park, it may be technically correct to call it a ``dog,'' but speakers tend to choose more specific or \emph{informative} expressions, like ``the little terrier with the blue collar'' \citep{VanDeemter16_ComputationalModelsOfReferring,GrafEtAl16_BasicLevel,BrennanClark96_ConceptualPactsConversation,DaleReiter95_GriceanRefs}. Similarly, a hyperbolic statement like ``I waited a million years for a table'' tends to be interpreted as an expression of frustration at longer-than-expected wait times rather than a literal statement about the time elapsed \citep{KaoWuBergenGoodman14_NonliteralNumberWords}.  %A doctor who uses a single Latinate term to tell their colleague about a condition may use many more words to tell a patient the same thing.  % Our success as a cooperative species depends upon our ability to make sense of other agents. 
This systematic contextual variation could in principle be accommodated by internally caching a complex set of different rules. 
But a key insight from the study of pragmatics is that many such phenomena can be more parsimoniously explained as the consequence of shared social reasoning mechanisms \citep{Grice75_LogicConversation, GoodmanFrank16_RSATiCS}. 
Just as making sense of an agent's physical movements in the world requires an accurate model of how beliefs and intentions translate into motor plans \citep{BakerSaxeTenenbaum09_ActionUnderstandingInversePlanning, JaraEttingerEtAl16_NaiveUtilityCalculus, BakerEtAl17_ToMBayesian}, making sense of language depends on an accurate mental model of what a speaker would say, or what a listener would understand, in different situations. 
In other words, communication depends on a flexible \emph{theory of mind} mechanism.

%While these failures are compelling evidence against a simple model where theory of mind reasoning is limited to literal perspective-taking, 
Past efforts to examine theory of mind use in communication have focused on a relatively narrow behavioral operationalization of theory of mind as perspective-taking about a partner's knowledge or visual access \citep{KeysarBarr___Brauner00_TakingPerspective, KeysarLinBarr03_LimitsOnTheoryOfMindUse, LinKeysarEpley10_ReflexivelyMindblind}. 
We argue in this paper that the mental models supporting theory of mind use in communication are richer than previously explored. 
In particular, we consider a class of mental models representing not only a partner's knowledge or visual access but also Gricean expectations of parsimony and cooperativity \citep{FrankeJager16_ProbabilisticPragmatics, Grice75_LogicConversation,Clark96_UsingLanguage,GoodmanFrank16_RSATiCS, FrankGoodman12_PragmaticReasoningLanguageGames, GoodmanStuhlmuller13_KnowledgeImplicature}: that speakers will avoid saying things that are confusing or unnecessarily complicated given the current context. 
%For example, suppose a friend wants to refer to a nearby Dalmatian. 
%There are numerous descriptions that would all be literally true, but different expressions are preferred in different contexts.
%If there are no other dogs nearby, we may expect them to use a parsimonious basic-level term like ``dog.''
%When there is potential for confusion, however, we expect them to consider our likely interpretation and introduce additional modifiers (``spotted dog'') or shift to more specific terms (``Dalmatian'') to disambiguate the one they are trying to refer to \citep{BrennanClark96_ConceptualPactsConversation, VanDeemter16_ComputationalModelsOfReferring, GrafEtAl16_BasicLevel}. 
%When speakers violate these expectations, listeners draw inferences about the intended meaning in order to account for the violation: for example, XXX \cite{XXX, BrehenyKatsosWilliams06_ImplicaturesOnline, StillerGoodmanFrank15_AdHocImplicature}. 

%This intricate dance of expectations has been formalized in a probabilistic model of communication as recursive social reasoning. The Rational Speech Act (RSA) framework has successfully described many puzzling communicative phenomena, including vagueness \cite{Lassiter}, hyperbole \cite{Kao}, irony \cite{}, metaphor, and apparent over-informativeness \cite{Judith}. In the simplest version of this framework, speakers judge the utility of different utterances proportionate to the probability of correct interpretation under an internal model of a listener. Listener, in turn, use their respective internal model of the speaker to reason backward to the most plausible intention \cite{Grice75_LogicConversation,Clark96_UsingLanguage,GoodmanFrank16_RSATiCSFrankGoodman12_PragmaticReasoningLanguageGames, GoodmanStuhlmuller13_KnowledgeImplicature}. 

%Since positive claims about theory of mind in communication concern the mental model we hold of our partner, these claims are best evaluated in a computational framework that formalizes the content of our representations and how we use them. We test a richer, more realistic theory of mind accounting not just for visual access but also for Gricean expectations of parsimony and context-appropriate informativity under uncertainty. Under this richer model, we find that behavior taken as evidence for limits on theory of mind reasoning is in fact precisely what is required by the pragmatics of the situation.

%Theory of mind mechanisms are the foundation of pragmatic accounts, especially as recently formalized in recursive reasoning models \cite{Grice75_LogicConversation,}, yet they have never been directly compared against the predictions of egocentric or ``mindblind'' theories under the same behavioral paradigm. 
%Since positive claims about theory of mind in communication concern the mental model we hold of our partner, these claims are best evaluated in a computational framework that formalizes the content of our representations and how we use them. 
%By rigorously comparing the predicted behavior of speakers and listeners using different mental models, we show that theory of mind is required to account for context-sensitive behavior. 
%In addition, we replicate effects that, under more naive behavioral measures, were interpreted as evidence of limits on theory of mind use, but under a richer computational model are shown to be rational consequences of an uncooperative confederate. 
%Especially in asymmetric communicative environments where speakers are explicitly put in a state of uncertainty over which objects their partner is seeing, evaluating the extent to which theory of mind is deployed in communication requires flexible mental models that represent the many sources of social expectations.
% While egocentric views of perspective-taking make more clear-cut behavioral predictions, the predictions derived from a computational theory of mind are more varied and complicated but ultimately more accurate.

%The underlying mechanisms that support our ability to communicate so flexibly and effortlessly? 

%speakers and listeners adapt their language use to their shared history and to the immediate context in rich, intricate ways \cite{Grice75_LogicConversation, Clark96_UsingLanguage}.  Listeners, for their part, draw ad-hoc implicatures based on expectations that speakers will give contextually sensitive descriptions \cite{BrehenyKatsosWilliams06_ImplicaturesOnline, StillerGoodmanFrank15_AdHocImplicature} and \dots

% While theory of mind use often appears to be automatic and effortless, Keysar and colleagues \cite{KeysarBarr___Brauner00_TakingPerspective, KeysarLinBarr03_LimitsOnTheoryOfMindUse, LinKeysarEpley10_ReflexivelyMindblind} have argued that it is actually the opposite, even for adults: we are ``mindblind" by default and only overcome our egocentric biases through an effortful process of perspective-taking. In other words, while adults are \emph{capable} of applying theory of mind reasoning, we do not always apply it reliably. 

% In this paper we argue that the apparent failures used to support this view are in fact successes for sophisticated social reasoning. 

%The argument offered by Keysar and colleagues is based on an elegant experimental paradigm, where participants played a simple communication game with a confederate. The two players were placed on opposite sides of a $4 \times 4$ grid containing a set of everyday objects (see Fig. \ref{fig:interface}). The confederate played the role of `director,' giving instructions about how to move objects around a grid, and the participant played the role of `matcher,' attempting to follow these instructions. For example, the objects in one trial included a cassette tape. The director gave an instruction like `move the tape up one square,' referring to the cassette.
%Critically, some objects were occluded such that only the matcher could see them, creating an asymmetry in the players' knowledge. To perform accurately on critical trials, the matcher would need to apply theory of mind to reason about which objects were shared and which were private. 
%For example, imagine a roll of tape were placed in an occluded slot: if a participant failed to account for the director's (partial) knowledge, she might interpret `tape' to mean the occluded roll of tape (which the director couldn't possibly know about). Indeed, \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse} found that participants attempted to move the hidden item in 30\% of cases: 71\% of participants attempted to move this hidden item at least once (out of four critical cases) in the experimental condition, compared to 0\% in a control condition where there was no ambiguity over the referent. 
%Additionally, eye-tracking data showed that participants considered the hidden item more often and for longer in the experimental condition than the control condition. 

% Discuss other criticisms of Keysar paradigm?
%While these results are compelling, the paradigm has been criticized from few different angles. 
%\cite{} have pointed out that in many cases, the hidden object was a better fit for the referring expression than the one in common ground (e.g. the hidden roll of tape vs. the cassette tape for ``the tape''), making the hidden object \emph{a priori} more likely to be the referent; it would generally be fairer to compare two objects that fit the referring expression equally well. 
%We validate this argument by empirically measuring relative fit of the expressions to the target and distractor items.
%Moreover,  argued that the viewpoint asymmetry paradigm is somewhat unnatural: common ground is typically built incrementally over the course of an interaction rather than presented all at once, and it is rare for a shared display to differ in perceptual accessibility. 

This suggests that we consider whether the scripted utterances produced by  confederates in influential perspective-taking tasks were actually what a speaker in that context would be expected to say \citep{KuhlenBrennan13_LanguageInDialogue}. 
If not, then perhaps listeners are making choices that are in fact consistent with a correct pragmatic interpretation of the confederate's (uncooperative) utterance.
More precisely, we hypothesize that when both players know that objects are occluded in context, pragmatic speakers may add additional precision to their references in order to avoid confusion. 
If a listener reasoning in this way justifiably expects the speaker to be more informative in context, they may \emph{rationally} adopt a ``perspective-neglecting'' strategy. % of choosing the \emph{a priori} more likely referent of the referring expression regardless of occlusion. 
We propose that it is precisely \emph{because} the listener uses theory of mind to form appropriate pragmatic expectations about the speaker's language use that they can be tricked by an uncooperative confederate into misunderstanding. 
%\begin{table*}
%\begin{center}
%\begin{tabular}{ p{2cm} | r | r |  r || r | r | r || r | r | r}
%& \multicolumn{3}{c||}{\% attempted at least once} & \multicolumn{3}{c||}{\% attempted at least twice} & \multicolumn{3}{c}{\% of total cases}\\
%\hline
%& Orig. & Expt. 1 & Expt. 2 & Orig. & Expt. 1 & Expt. 2 & Orig. & Expt. 1 & Expt. 2  \\
%Experimental & 71 & 93 & 61 & 46 & 57 & 32 & 30 & 43 & 24\\
%Baseline        & 0   & 7   & 0   & 0   & 0   & 0   & 0   & 2   & 0\\
%\end{tabular}
%\caption{Side-by-side comparison of error rates in \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse} and our two replications. The first two sections show the percentage of \emph{participants} attempting to move the occluded distractor at least once, or twice, of the four possible cases. The third section shows the percentage of \emph{all experimental trials} that the participant actually tried to move the occluded object. }
%\label{table:mainResults}
%\end{center}
%\end{table*}
%
%We began by replicating \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse} in a multi-player web experiment. We recruited participants to be both director and matcher (instead of using a confederate), but instructions for critical items, as well as a random subset of filler items, remained scripted as in the original study. We replicated the original finding, but noted a tendency of directors to be overinformative in unscripted filler trials. We then ran the same experiment without using any scripted instructions, observing unconstrained director utterances. We found much greater precision in unconstrained director utterances, which match targets much better than distractors, and better performance of the matchers. This minimal pair of experiments demonstrates that listener mistakes are at least partially due to the pragmatics of the task, ironically showing that apparent failures of theory of mind are in fact attributable to sophisticated expectations about speaker behavior---that is, to theory of mind.

%In particular, we argue that critical utterances used by Keysar and colleagues are \emph{uncooperative}: they are less informative than what a speaker would actually produce in that situation; listeners who are sensitive to the pragmatics of the situation expect these more informative utterances and produce ``errors'' when their expectations are flouted.
In Experiment 1, we conduct a direct replication of \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse}, manipulating whether the speaker is a confederate or naive participant. We find that unscripted speakers naturally produce more informative utterances than those in the confederate's script, and that listeners consequently make fewer errors. In Experiment 2, we manipulate the presence or absence of occlusions in context to directly pinpoint the speaker phenomenon of occlusion sensitivity. We show for the first time that speakers systematically produce longer, more specific utterances than strictly required by their visible context when they have uncertainty about what their partner is seeing. Thus, listeners are rationally justified in ignoring perspective and relying on informative utterances.
Taken together, these results suggest that apparent failures of perspective-taking are in fact attributable to sophisticated pragmatic expectations about speaker behavior---that is, to successful theory of mind use.

\subsection{Experiment~1: Direct replication}
\label{sec:Exp1}

\subsection{Participants}

We recruited 368 participants (196 pairs) from Amazon Mechanical Turk to play an interactive communication game using the framework described in \cite{Hawkins15_RealTimeWebExperiments}. 58 pairs were unable to complete the game due to a server outage. Following our preregistered exclusion criteria\footnote{Unless otherwise mentioned, all analyses and \dots are preregistered at \textrm{https://osf.io/qwkmp/}}, we also removed 13 games who reported confusion or made two or more errors on filler items and 2 additional games containing non-native English speakers. This left 127 pairs in our final sample. \todo[inline]{TODO: also mention removal of 3 games only using location or using 'taboo' utterances (i.e. cryptic clues).}

\begin{figure}[t!]
 \begin{center}
 \vspace{-.25cm}
 \includegraphics[scale=.38]{figures/Exp1_design.pdf}
 \vspace{-.5cm}
 \caption{Screenshots of interface on a critical trial: a cassette tape is in view of both players, but a roll of tape is occluded from the speaker's view.}
 \vspace{-.5cm}
 \label{fig:exp1paradigm}
 \end{center}
 \end{figure}
 
\subsection{Materials \& Procedure}

%To deal with participants arriving at unpredictable times, we implemented a waiting room mechanism, where the first person to enter the game environment would see a screen saying ``Waiting for another player..." and the second person would trigger the game to start. 
Participants in each pair were randomly assigned to `director' and `matcher' roles and placed in a shared environment containing a chat box and a $4 \times 4$ grid of objects (see Fig. \ref{fig:exp1paradigm}). Trials were blocked into eight `items', each using a different set of objects. For each item, we gave the director a series of four instructions, which were displayed as a series of arrows pointing from some object to a neighboring unoccupied cell. They used a chat box to communicate the identity of this object and action to their partner, who proceeded to click and drag an object to complete the trial. In each blocked set of objects, one target belonged to a `critical pair' of objects, such as a visible cassette tape and a hidden roll of tape that could both plausibly be referred to as `the tape.'

We used a between-subject design to test whether the scripted labels used by confederates were in fact comparable to what cooperative speakers would say in context. Directors assigned to the `scripted' condition were free to communicate however they wished for half of the instructions. For the other half, including all the critical instructions, their messages were pre-scripted using the precise wording from \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse}. For example, when giving instructions on how to move the cassette tape, the director would be forced to use the ambiguous utterance ``Move the tape down one square."\footnote{That is, in these conditions, the scripted message would automatically appear in the director's chat box, and they would have to click `send' for the experiment to continue.} In the `unscripted' condition, directors were unrestricted and free to send whatever messages they deemed appropriate on all trials. 

We collected baseline performance for each condition by replacing the hidden alternative (e.g.~a roll of tape) with an object that did not fit the critical instruction (e.g.~a battery); we used the same unambiguous replacements as \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse}. Each participant was shown half of the items in the experimental condition and half in the baseline condition. The assignment of items to conditions was randomized across participants, and the order of conditions was randomized under the constraint that the same condition would not be used on more than two consecutive items. Five of the grid cells were blocked from the director's view by a curtain, and six or seven objects were displayed in the grid at a given time. All object sets, object placements, and corresponding instruction sets were fixed across participants. 

In addition to collecting messages sent through the chat box and matcher errors, we collected mouse-tracking data in analogy to the eye-tracking common in these paradigms. To collect the cleanest possible data, we asked the matcher to wait until the director sent a message; when the message was received, the matcher clicked a small circle in the center of the grid to show the objects and proceed with the trial. We recorded at 100Hz from the matcher's mouse in the decision window after this click, until the point where they clicked and started to drag one of the objects. 

%On half of the instruction sets (the `critical' condition), the critical distractor object was placed in an occluded slot such that it was only visible to the matcher; on the other half (the `baseline' condition), all hidden distractors were unrelated fillers. 


%Before entering the game environment, every participant independently passed a short quiz about the task's instructions, ensuring that they understood the interface. %Among other items on the quiz, we verified that both participants understood that items behind black cells were only visible to the matcher. 


%The argument offered by Keysar and colleagues is based on an elegant experimental paradigm, where participants played a simple communication game with a confederate. The two players were placed on opposite sides of a $4 \times 4$ grid containing a set of everyday objects (see Fig. \ref{fig:interface}). The confederate played the role of `director,' giving instructions about how to move objects around a grid, and the participant played the role of `matcher,' attempting to follow these instructions. For example, the objects in one trial included a cassette tape. The director gave an instruction like `move the tape up one square,' referring to the cassette.
%Critically, some objects were occluded such that only the matcher could see them, creating an asymmetry in the players' knowledge. To perform accurately on critical trials, the matcher would need to apply theory of mind to reason about which objects were shared and which were private. 
%For example, imagine a roll of tape were placed in an occluded slot: if a participant failed to account for the director's (partial) knowledge, she might interpret `tape' to mean the occluded roll of tape (which the director couldn't possibly know about). Indeed, \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse} found that participants attempted to move the hidden item in 30\% of cases: 71\% of participants attempted to move this hidden item at least once (out of four critical cases) in the experimental condition, compared to 0\% in a control condition where there was no ambiguity over the referent. 
%Additionally, eye-tracking data showed that participants considered the hidden item more often and for longer in the experimental condition than the control condition. 

\subsection{Results}

 \begin{figure}[t!]
 \begin{center}
 \vspace{-.25cm}
 \includegraphics[scale=1]{figures/Exp1_listener_results.pdf}
 \vspace{-.5cm}
 \caption{Listener results for Exp.~1. (A) Errors distributions with scripted and unscripted instructions -- participants in the unscripted condition made significantly fewer errors. (B) Even when made the correct response, listeners in the scripted condition were more likely to hover over the distractor relative to baseline while the unscripted condition shows no difference. Error bars are bootstrapped 95\% confidence intervals.}
 \vspace{-.5cm}
 \label{fig:exp1listener}
 \end{center}
 \end{figure}

\subsubsection{Listener errors}

Our scripted condition successfully replicated the results of \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse} with even stronger effects: listeners attempted to move the hidden object on approximately 50\% of critical trials. However, listeners attempted to move the hidden object less than half as often when their partner was able to produce natural referring expressions, $p_1 = 0.51, p_2 = 0.20, \chi^2(1) = 48.5, p < 0.001$ (Fig. \ref{fig:exp1listener}A). We also found substantial heterogeneity in errors rates across items, which diverge significantly from a uniform distribution in both scripted ($\chi^2=55, p < 0.001$) and unscripted ($\chi^2=36, p <0.001$) conditions under a non-parametric $\chi^2$ test (see Supplemental Fig. \ref{fig:error_heterogeneity}). Still, listeners in the unscripted condition made fewer errors for nearly every item, some more dramatically than others. A maximal mixed-effects logistic regression with random intercepts for each dyad and random slopes and intercepts for each item shows a significant effect of condition ($z = 2.856, p = 0.004$). %For items where participants 
%For example, 75\% of participants made an error on item 6 upon hearing the scripted instruction ``the eraser'' while only 17\% of participants in item 8 made an error upon hearing ``the mouse.'' 

%This item-wise variability suggests that the dependent variable highlighted in the original study (i.e. ``percentage of participants who moved the critical item at least once'') is somewhat problematic: it could look like 100\% of participants made errors even if they all made those errors on one particularly difficult item. Indeed, if we exclude the three `hard' items where over 60\% of participants in the experimental condition made errors, this dependent variable drops from 93\% to only 43\% of participants. 
%This suggests that the ``at least one error'' DV is not appropriate in settings with high variability across items and that we might want to be more careful about controlling for this variability, perhaps by first measuring salience and ambiguity without the occlusion aspect of the paradigm.

Even if participants in the unscripted condition make fewer actual errors, they may still be \emph{considering} the hidden object just as often on trials where they go on to make correct responses. As a proxy for the eye-tracking analyses reported by \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse}, we therefore conducted a mouse-tracking analysis. Mouse position is highly correlated with gaze in web browsing \citep{ChenEtAl01_MouseCursor, SpiveyGrosjeanKnoblich05,RoddenEtAl08_EyeMouseCoordinationWebSearch} but precise timing can be difficult and unreliable to measure. 
So we used as our dependent variable the proportion of critical instructions that participants hovered over (or `fixated on') a hidden distractor.
\footnote{We preregistered as our dependent variable the mean \emph{amount of time} spent hovering over hidden distractor, but because this DV was exactly zero for the majority of trials and a large, highly variable number for the rest of trials, we decided post-hoc that the mean was not as meaningful as the binarized version. Still, regression results are unchanged when conducted on log-transformed hover times.} 
We found that listeners in the \emph{scripted} condition hovered over the hidden distractor on over 30\% of critical trials relative to a baseline of 10\% when the hidden object was an unrelated filler, again replicating \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse}. In the unscripted condition, however, there was no difference from the baseline. We found a significant interaction in a maximal mixed-effect model with dyad-level and object-level random intercepts and a dyad-level random effect for the difference from baseline ($z = -2.8, p = 0.004$; Fig. \ref{fig:exp1listener}B). %predicted that even when participants went on to make a correct decision, they would be 
%We define the decision window as the span of time between  their instruction message and when they started moving an object. If it took them multiple attempts to move the correct object, we restricted our analysis to the first attempt. 
% Within the decision window, we computed the total proportion of time spent moving toward the target relative to the distractor. %We had to exclude an additional 3 participants for this analysis, because the timestamps for director and matcher did not align and we could not establish the decision window properly. 
%A paired-samples $t$-test found that matchers in the scripted condition tended to spend less time hovering over the target cell on critical experimental trials than on baseline trials, $t(10) = -2.65, p = 0.02$ (see Fig. \ref{fig:hover}), indicating that the presence of a hidden distractor interfered with participants ability to directly choose the target.%\footnote{This analysis includes participants who actually made errors, since the data is too sparse to exclude them.} . %accounts for a significant proportion of variance $F(3, 52) = 10.7, p < 0.001$

%When we conducted a mouse-tracking analysis identical to the one reported for Expt.~1, we found no significant decrease in target hover time between experimental and baseline trials $t(27) = 0.89, p = 0.38$. To directly test for differences in hover time patterns across the two experiments, we used a mixed-effects model with a random intercept for game ID and an interaction between condition and experiment on target hover time. We found a marginally significant interaction, $b = 0.09, t = 1.89, p = 0.066$ (see Figure \ref{fig:hover}), providing some evidence that the presence of a hidden distractor no longer interfered target selection in Expt~2.

\subsubsection{Speaker informativity}

 \begin{figure}[t!]
 \begin{center}
 \vspace{-.25cm}
 \includegraphics[scale=1]{figures/Exp1_speaker_results.pdf}
 \vspace{-.5cm}
 \caption{Speaker results for Exp.~1. (A) While scripted utterances were judged to fit target and distractor roughly equally, speakers in the unscripted condition naturally produced utterances that fit the target much better than the distractor. (B) The extent to which an utterance fits the target more than the distractor is highly predictive of error rates at an item-by-item level. All error bars are bootstrapped 95\% confidence intervals.}
 \vspace{-.5cm}
 \label{fig:exp1speaker}
 \end{center}
 \end{figure}
 
Next, we test whether these improvements in listener performance are in fact due to more informative speaker behavior in the unscripted condition. %By running this replication as a multi-player web experiment we have available an additional source of data beyond the original experiments: half of the instructions were unscripted, providing observations of natural production of referential descriptions for filler items. 
%First, on filler trials in both conditions, we noted a tendency toward additional, possibly unnecessary, precision in descriptions. For example, instead of saying ``move the plane to the right'' when there is only one plane, participants said ``move the red airplane to the right.'' 
%Perhaps directors were taking the time to make more precise descriptions because they believed it was contextually relevant: both parties know that there are hidden objects in the environment increasing the chance of miscommunication from imprecise descriptions. 
%If the matcher expected the director to be precise, then they would be justified in picking the first or best object that meets the description (rather than worrying excessively about occluded cells). 
%That is, the scripted instructions used by the director for critical trials may have been \emph{uncooperative} for this situation, and thus led matchers astray. 
%We therefore expected to see more precise descriptions by unscripted directors and fewer errors by matchers in the critical trials.
The simplest measure of speaker informativity is the raw number of   words used in referring expressions. Compared to the scripted referring expressions, speakers in the unscripted condition use significantly more words to refer to critical objects ($b = 0.48, t = 2.5$ in a mixed-effects regression on difference scores with a fixed intercept and random intercepts for object and dyads.) However, this is a very coarse measure: the short ``pyrex glass'' may be more specific than ``large measuring glass'' despite using fewer words, and more words doesn't necessarily mean more information.
\todo[inline]{We can remove the above analysis for space if necessary}

For a more explicit measure, we extracted the referring expressions generated by speakers in all critical trials and standardized spelling and grammar, yielding 123 unique labels after including scripted utterances. We recruited 20 judges on Amazon Mechanical Turk to rate whether each label was true of the target and hidden distractor objects. They were shown objects in the context of the full grid (with no occlusions) such that they could feasibly judge spatial or relative references like ``bottom block.'' Responses were given on a slider with endpoints labeled ``strongly agree'' and ``strongly disagree.''  After excluding 4 judges for guessing with response times $< 1s$, inter-rater reliability was relatively high, with intra-class correlation coefficient of $0.54 (95\% CI = [0.47, 0.61])$. Because all judges rated all utterances for both target and distractor, we could compute the \emph{informativity} of an utterance as the difference score between target and distractor responses.

Our primary measure of interest is the difference in informativity across conditions. Due to the complexity of the multiple partially crossed levels of variability in our data, standard mixed-effects models were not appropriate. Instead, we used a multi-stage, non-parametric bootstrap to compute 95\% confidence intervals. We found that speakers in the unscripted condition systematically produced utterances with higher informativity ratings than the scripted utterances ($m = 0.5$, 95\% bootstrapped CI = $[0.23, 0.78], p < .001$; see Fig. \ref{fig:exp1speaker}A). Scripted labels fit the hidden distractor just as well or better than the target, but unscripted labels fit the target much better and the hidden distractor much worse. In other words, the scripted labels used in \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse} were less informative than speakers normally produce in this context. 

%While a naive perspective-taking account would predict no relationship, a perspective-negligence account predicts that listeners simply pick the object that fits the description best regardless of whether it is hidden or not.
Finally, we consider the link between the speaker and listener behavior we observed across condition. To what extent does the informativity of speaker utterances account for the substantial variance across items we observed in listener errors in the two conditions? We found a strong negative correlation between informativity and error rates: listeners make fewer errors when utterances are a better fit for the target relative to the distractor ($\rho = -0.8$, bootstrapped 95\% CI $= [-0.89, -0.69]$; Fig. \ref{fig:exp1speaker}B). This suggests that reference disambiguation was driven primarily by \emph{a priori} label fitness rather than consideration of occluded vs. mutually visible items. 
 %  We used a mixed effects logistic regression model to estimate the effect of target and distractor fit on the probability of making a critical error in both experiments, including a random intercept for game ID. We found that participants are less likely to make errors when informativity is higher. Furthermore, a model including target fit and distractor fit in addition to item-level fixed effects is significantly better than a model including item alone, $\chi^2(2) = XXX, p < YYY$, implying that speaker informativity captures residual variance beyond the item-wise effects reported above.
\todo[inline]{rxdh: I think this bootstrapped correlation stat at the objectSet-condition level makes this point well enough for our purposes (it's a pretty huge effect...), but I could also do a fancier thing boostrapping logistic coefficients at the trial-by-trial level if necessary. }
\todo[inline]{rxdh: also, is it worth having a short appendix with more details on the multi-stage bootstrapping procedure? it's very straightforward but takes a few sentences to explain\dots}

% \begin{figure}[t!]
% \begin{center}
% \vspace{-.25cm}
% \includegraphics[scale=.55]{images/itemwisefitness.pdf}
% \vspace{-.75cm}
% \caption{Item-wise error rates compared with label fitness ratios, across both experiments. Error bars are bootstrapped 95\% confidence intervals for fitness and 95\% highest posterior density intervals for error rates.}
% \vspace{-.5cm}
% \label{fig:itemLevel}
% \end{center}
% \end{figure}

%A large body of evidence has demonstrated striking failures of perspective-taking, where listeners appear to be ``mind-blind,'' neglecting the visual access of their partner when interpreting their utterances 

%The experiment proceeded through all eight items, with the director providing instructions and the participant moving the objects. Except for instructions with scripted messages, the participants were free to use the chat box for questions, small talk, or whatever else.
% \begin{table*}
% \begin{center}
% \begin{tabular}{ m{1cm} | m{1.5cm} | m{1.5cm} | m{1.5cm} |  m{1.25cm} | m{1.6cm} | m{1.4cm} | m{1.1cm} | m{1.3cm} | m{1.3cm} |}
% & & Item 1 & Item 2 & Item 3 & Item 4 & Item 5 & Item 6 & Item 7 & Item 8\\\hline
% & instruction & ``glasses'' & ``bottom block'' & ``tape'' & ``large measuring cup'' & ``brush'' & ``eraser'' & ``small candle'' & ``mouse'' \\\hline
% & target & sunglasses & block (3rd row) & cassette & medium cup & round hairbrush & board eraser & medium candle & computer mouse \\\hline
% & hidden distractor & glasses case & block (4th row) & scotch-tape & large cup & flat \,\,\,hairbrush & pencil eraser & small candle & toy mouse \\
%  \hline\hline
% \multirow{2}{.75cm}{Expt.~1}  & \# incorrect & 0 & 5 & 1 & 3 & 2 &6 & 6 & 1 \\ 
%                                                & \# correct & 6 & 3 & 1 & 8 & 2 & 2 & 4 & 6 \\
%  \hline\hline
% \multirow{2}{.75cm}{Expt.~2} & \# incorrect & 0 & 1 & 1 & 3 & 9 & 7 & 1 & 5 \\
%                                               & \# correct   & 12&14&11&13&7 &8   &12& 8 \\

% \end{tabular}
% \vspace{-.5cm}
% \caption{Item-wise error rates for critical trials}
% \vspace{-.25cm}
% \label{table:ItemWise}
% \end{center}
% \end{table*}

%Third, none of the experiments reported by Keysar and colleagues included a key comparison condition where the critical item (e.g. the roll of tape) was \emph{also} in common ground \cite{BrownSchmidtHanna11_IncrementalPerspectiveTaking}---perhaps people would refer to the critical item less in the privileged condition than in the full common ground condition, which would put a more positive spin on the results. %Note that none of these criticisms invalidate the paradoxical result that listeners move an occluded object, they just suggest an alternative explanation. Reference disambiguation is probabilistic: common ground and goodness of fit are weighed against one another.

\subsection{Discussion}

In both raw patterns of error and mouse-tracking metrics, we successfully replicated the findings of \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse}. Participants frequently attempted to move the occluded alternative when it matched the target referential expression, even though the director couldn't possibly have been referring to it. And even on trials where they moved the correct object, matchers were more likely to hover their cursor over the occluded cell. Furthermore, by considering utterance informativity, we found that patterns of errors across items are well-predicted by relative fit to the target vs. distractor. Taken together, these results support the claim that listeners neglect the speaker's perspective in some contexts. 

At the same time, however, our \emph{speaker} results suggest a deeper explanation for the phenomenon of perspective-neglect. We found a tendency toward additional, possibly unnecessary, informativity in speaker descriptions. For example, instead of the scripted ``move the \emph{brush} one square to the right'' which would be sufficient with only one brush in their display, speakers instead chose to give descriptions like ``move the \emph{hairbrush with two lines on the handle} to the right.'' 
Perhaps speakers were taking the time to make more precise descriptions than required by their own immediate display because they believed it was contextually relevant. 
In particular, speakers know that there additional objects of unknown identity in their partner's field of view, potentially increasing the risk of miscommunication from imprecise descriptions. 
If natural speakers do adaptively produce more informative descriptions in context, then pragmatic listeners rationally expecting speakers to do so may be justified in weighting considerations of the speaker's visual perspective less strongly. 

\subsection{Experiment~2: Production in uncertain contexts}
\label{sec:Exp2}

In Experiment 2, we more directly test the hypothesis that speakers adaptively increase the informativity of their referring expressions in more \emph{uncertain} contexts where items are occluded. The idiosyncracies we observed among the linguistic items used in Expt. 1 make it difficult to normatively assess pragmatic `increases' in informativity for a given target. For example, when unscripted participants used an additional modifier (`cassette tape') to describe the target tape in one item, it happened to be highly informative relative to the distractor (a roll of tape). Adding a similar modifier (`hair brush') to describe the target in another item, however, was ineffective because both the target and distractor are hair brushes that are confusable at the subordinate level (one is round and one is flat). For this experiment, then, we move to a more systematic, feature-based stimulus domain and manipulate the presence or absence of occluders.

\subsection{Participants}

We recruited 204 participants (102 pairs) from Amazon Mechanical Turk. After we removed 7 games that disconnected part-way through and 12 additional games according to our pre-registered exclusion criteria (due to being non-native English speakers, reporting confusion about the instructions, or clearly violating the instructions), we were left with a sample of 84 full games. 

\subsection{Materials \& Procedure}

  \begin{figure}[t!]
 \begin{center}
 \vspace{-.5cm}
 \includegraphics[scale=.35]{figures/Exp2_design.pdf}
 \caption{Within-pair factorial design used in Exp.~2. In the common condition, we reproduce a simple pragmatic reference contrast: when more than one star is present in common ground, speakers are expected to be more informative. On hidden versions of these condition, the same set of objects is visible, but some additional squares are occluded. If pragmatic directors represent uncertainty over what the matcher sees behind these squares, we predict that they will produce more informative utterances. \todo[inline]{TODO: Use screenshots of real displays instead of cartoon.}}
 \vspace{-.5cm}
 \label{fig:exp2design}
 \end{center}
 \end{figure}
 
Stimuli varied along three discrete features: \emph{shape}, \emph{texture}, and \emph{color}. Each feature took four discrete values, giving a space of 64 possible objects. We placed these objects in a smaller $3 \times 3$ grid, and used a pure \emph{reference game} setup where listeners had to click the intended referent as opposed to following a movement instruction. 

Our design is entirely within-pair. Each trial is sampled from a factorial 2 x 2 design manipulating (1) the presence or absence of occlusions (`hidden' vs. `no hidden'), and (2) the closeness of \emph{visible} distractors to the target (`close' vs. `far'; see Fig. \ref{fig:exp2design}). On `hidden' trials, two cells were covered in curtains such that only the matcher can see if there is an object in the cell; on 'no hidden' trials, all cells are in common ground. On 'far' trials, the target is the only object with a particular shape; on 'close' trials, there is also a visible distractor sharing the target's shape, differing only in color or texture. Each trial type appeared 6 times for a total of 24 trials, and the sequence of trials was pseudo-randomized such that no trial type appeared more than twice in each block of eight trials. 

\subsection{Results}

 \begin{figure}[t!]
 \begin{center}
 \vspace{-.25cm}
 \includegraphics[scale=1.25]{figures/Exp2_results.pdf}
 \vspace{-.5cm}
 \caption{Results for Exp.~2. (A) Speakers used significantly more words when occlusions were present, and effect is even greater than the standard pragmatic effect of being in a close vs. far context (B) Utterances broken out by feature mentioned. All error bars are bootstrapped 95\% confidence intervals.}
 \vspace{-.5cm}
 \label{fig:exp2results}
 \end{center}
 \end{figure}

Listener errors were rare and unstructured: 88\% of listeners made one or fewer errors, and there was no significant difference in error rates across the four conditions ($\chi^2(3) = 1.23, p = 0.74$). Because this experiment was designed to investigate speaker pragmatics, we focus our attention on how speaker behavior adjusted flexibly from context to context.

Our primary measure for speakers is the length (in words) of naturally produced referring expressions. We conducted a mixed-effect regression of context and occlusion on number of words with maximal random effect structure containing intercept, slopes, and interaction. First, we examined the \emph{simple} effect of close vs. far contexts in trials with no occlusions. We found that speakers used significantly more words on average when there was a distractor in context that shared the same shape as the target ($b = 0.56, t = 5.1, p < 0.001$; see Fig. \ref{fig:exp2results}A). This replicates the findings of classic studies with similar designs \cite[e.g] {BrennanClark96_ConceptualPactsConversation, GrafEtAl16_BasicLevel, MonroeEtAl17_ColorsInContext}. Next, we turn to the simple effect of occlusion in far contexts (which are most similar to the displays used in Expt.~1). The average speaker used 1.25 additional words when they knew their partner could potentially see additional objects ($t = 7.5, p < 0.001$). Finally, we found a significant interaction ($b = -0.49, t = 3.8, p <0.001$) where the effect of occlusion was larger in far contexts, likely indicating a ceiling on the level of informativity possible in our simple stimulus space.

What are these additional words spent on describing? As a secondary analysis, we annotated each utterance by which object features were mentioned (shape, texture, color). Speakers nearly always mentioned shape  (e.g. `star', `triangle') as the head noun of their referring expression regardless of context, so differences in words across conditions must be due to providing additional information about color and texture. We ran separate mixed-effect logistic regressions for color and texture predicting mention from context; due to well-known convergence issues in logistic models, the maximum random effect structure supported by our data contains only speaker-level intercepts and slopes for occlusion. In both cases, we found simple effects of occlusion in far contexts ($b = 1.33, z = 2.9, p = 0.004$ for color; $b = 2.1, z = 5.7, p < 0.001$ for texture, see Fig. \ref{fig:exp2results}B). In other words, in displays like the one in Fig. \ref{fig:exp2results}A where the target was the only `star', speakers were slightly more likely to produce the star's color---and substantially more likely to produce its texture---when there were occlusions present, even though the visible objects were exactly the same. 

\todo[inline]{Say something about the small population of 10 or so speakers who adopted the strategy of mentioning every feature every time?}

\subsection{Discussion}

We found in Expt.~1 that speakers naturally produced more informative utterances than would be necessary given the set of objects in their visual field. In Expt.~2 we directly tested the hypothesis that increased informativity is due to uncertainty about the listener's view imposed by the presence of occlusions. By manipulating occlusions, we found that speakers are not only context-sensitive in choosing referring expressions that are appropriately distinguishing in a shared context, but also \emph{occlusion-sensitive} in adaptively compensating for additional uncertainty by adding additional information. These forms of sensitivity are difficult to explain under an egocentric theory: speakers were spontaneously willing to spend additional time and keystrokes to give information that would be redundant given the set of objects visible in their own display. 

%\section{Evaluating models of referring}
%
%\subsection{Pure egocentrism}
%
%The simplest strategy for a speaker attempting to refer to a target object $o_i$ is to produce the simplest label that best fits $o_i$, effectively ignoring context and listener knowledge. \todo[inline]{rxdh: technically, mean soft-max here...} Similarly, the simplest strategy for a listener is to pick the object in their view that is best described by the utterance, ignoring the visual access or pragmatic goals of the speaker. These models are purely egocentric, in the sense that they do not engage in any social reasoning. 
%
%\subsection{Pure consideration of visual access}
%
%The most immediate model of social reasoning is consideration of the informativeness of a label in a shared context containing many objects. For a speaker, this means preferring labels that are good fits for the target but \emph{not} known distractors in common view. For instance, when referring to a dog in the shared context of other dogs, a speaker may opt to be more informative than simply saying `dog,' since it is ambiguous. For a listener, this means discounting objects that are not in shared context, regardless of how well the description fits. These are not available to the visual access of the speaker and thus not viable referents. 
%
%\subsection{Probabilistic weighing of perspectives}
%
%Rather than taking a purely egocentric perspective or purely considering a partner's visual access, speakers or listeners may be probabilistically integrating these two perspectives \cite{HellerParisienStevenson16_ProbabilisticWeighing}. % When conversational expectations lead participants to expect over-informative utterances, they (rationally) place relatively less weight on features of the environment determining common ground, such as shared perceptual access. 
%
%\subsection{Gricean communication under uncertainty}
%
%We begin by considering the problem faced by a speaker who wants their partner to select a target object from a context containing other potentially similar objects. %  a simple probabilistic model of reference in the rational speech act (RSA) model. 
%
%where speakers produce informative utterances by reasoning about a rational listener agent who updates their beliefs about the world according to the literal semantics of the language. This allows us to test pragmatic accounts of task performance. 
%
%Pragmatic critiques of the director-matcher task point to an additional source of uncertainty that has not previously been explored: uncertainty over a communication partner's visual context. Considering this uncertainty, of course, \emph{is} theory of mind in action; our goal is to show how such a model built on social reasoning can produce the `failures' found by \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse} as well as the phenomena observed by both \cite{HawkinsGoodman16_Keysar} and \cite{RubioFernandez16_DirectorTaskAttention}. For simplicity, we consider the full $2\times 2$ grid containing a single occluded cell, which was used by \cite{RubioFernandez16_DirectorTaskAttention}. We incorporate this source of uncertainty into both the speaker and listener models as follows:
%
%\begin{enumerate}
%\item A pragmatic speaker perceives an array of three objects $\mathcal{O}_S = \{o_i\}$, one of which is identified as a target $t$, but assumes that their partner sees an additional hidden object $o_h$ that is not in common ground. The speaker has uncertainty over the identity of this object, represented by a prior distribution $P(o_h)$ which they marginalize over when deciding what utterance to produce:
%$$S_1(u | t, \mathcal{O}_p) \propto \sum_{o_h} L_0(t| \mathcal{O}_S \cup \{o_h\})P(o_h)P(u)$$
%
%%\item A pragmatic listener, reasoning about this uncertain speaker, is presented with a full array of four objects $\mathcal{O}_L$, one of which is identified as hidden to the speaker, $o_h$. The listener, however, also has some uncertainty over whether the experimenter is deceptive, represented by a Bernoulli random variable $d$, such that they assign a small prior probability $P(d)$ to the possibility that $o_h$ is actually in common ground. Upon hearing an utterance$u$, they update both their beliefs about which object is the target and whether the experimenter is being deceptive:
%%$$L_2(t, d | u, \mathcal{O}_L) = P(t)\left(S(u | t, \mathcal{O}_L)P(d)\right)^d(S(u | t, \mathcal{O}_L - o_h)(1-P(d))^{1-d}$$
%\end{enumerate}
%Technical details are omitted here for brevity, but the full model is fully specified in WebPPL and available to run at %\url{http://forestdb.org/models/keysar.html}. 
%
%We focus on two critical patterns of results produced by the pragmatic listener $L_2$. First, we consider how it responds to the scripted instruction ``fish'' when presented with a context containing two fish (a red one that is occluded and a blue one in common ground) as well as two other unrelated objects. While it is most likely to choose the red fish in common ground, it has a relatively high probability (43\%) of choosing the hidden red fish, an effect \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse} claimed was due to failure of theory of mind. This decision emerges in the model for two primary reasons. For one, a speaker with uncertainty over context could in principle be communicating about any object, and if they believed the hidden object was a red fish, the utterance `fish' would have a high probability of being produced. To a lesser extent, context uncertainty makes the overinformative utterance `blue fish' more likely than `fish', hence the omission of the color modifier has the (subtle) implication of \emph{not} the blue fish. This speaker phenomenon, while subtle under the parameter regime of the current implementation, produces the dynamic observed in the unscripted replication by  \cite{HawkinsGoodman16_Keysar}.
%
%Second, we consider the listener's posterior over the \emph{deception} Bernoulli variable $d$. Just as \cite{RubioFernandez16_DirectorTaskAttention} found that listeners were more likely to suspect deception after hearing an `overinformative' utterance like `blue fish' when only one fish was in common ground, so too does our pragmatic listener. The pragmatic speaker is relatively more likely to produce the additional color modifier if they see multiple fish than when they see a single fish and simply have uncertainty over the unknown object. Hence, our model simultaneously captures all three phenomena. 

\section{General Discussion}

The rational use of theory of mind for a listener extends well beyond simple consideration of who sees what; it depends on her ability to reason holistically about the speaker's likely communicative behavior in context. 
%Pragmatic language understanding depends upon social reasoning. To interpret an utterance, a listener must consider how a speaker is likely to behave in context; to produce an utterance, a speaker must consider how the listener is likely to understand it.
In this paper, we considered the hypothesis that successes in this broader Gricean application of theory of mind may ironically explain apparent failures to account for visual perspective. 
In a direct replication, we found strong empirical support for the claim that listeners neglect the speaker's perspective in some contexts. 
Rather than debating the existence of this phenomenon, then, we suggested an alternative, non-egocentric explanation of \emph{when} and \emph{why} listeners may neglect speaker perspective in the first place. 
In particular, while the scripted instructions in Exp.~1 systematically violated Gricean expectations of cooperativity, natural speakers did not. They appropriately increased the informativity of their referring expressions to account for occlusions in context. 
Our demonstrations of speaker occlusion-sensitivity thus provide justification for relying on speakers to be informative.

% 1. Tying back to original expt (e.g. pitch Expt. 3 idea). 
If visual perspective-taking is as effortful and cognitively demanding as claimed \cite{LinKeysarEpley10_ReflexivelyMindblind}, then pragmatic reasoning may play an important role in how listeners rationally allocate their resources during communication \cite{GriffithsLiederGoodman15_LevelsOfAnalysis}. Using theory of mind to form early expectations about how speakers are likely to behave in context allows listeners to adopt a more efficient strategy in the long-term. An important direction for future work, then, is to evaluate the causal role of pragmatic reasoning by directly manipulating the listener's Gricean expectations. We hypothesize that listeners would flexibly choose to rely more heavily on perspective information if they could not rely on their partner to be cooperative. In fact, one explanation for why error rates in our replication were higher than the original is the influence of the `filler' trials where speakers in the scripted condition were allowed to freely produce referring expressions. Many speakers were producing long, highly informative utterances in these filler trials, potentially setting up strong expectations for cooperativity that were then flouted in critical trials.

%These reasons stem from more sophisticated pragmatic expectations than simple consideration of perspective, thereby opening a deeper avenue by which theory of mind use guides flexible communication. % if speakers could be expected to naturally provide expressions which apply better to the target, then this behavior would be appropriate. a listener expects a speaker to provide sufficiently informative utterances, she may be justified in neglecting his visual perspective when resolving reference. We predict that 

%However, this finding does \emph{not} necessarily imply limitations on theory of mind. Speakers systematically provide more informative utterances in contexts where views are uncertain, hence listeners with well-calibrated social expectations are justified in neglecting perspective.
There is a long history of debate over both the methods and interpretation of the director-matcher task \cite[e.g.]{HannaTanenhausTrueswell03_CommonGroundPerspective, HannaTanenhaus04_PragmaticEffects, HellerGrodnerTanenhaus08_Perspective, BrownSchmidtTanenhaus08_TargetedGame}. Our findings are particularly resonant with several recent results. \cite{RubioFernandez16_DirectorTaskAttention} secretly scrambled occlusions across the speaker's and listener's screens to create a mismatch in expectations about which objects are shared. Listeners were able to gradually infer this manipulation from the speaker's choice of referring expressions, implicating Gricean theory of mind reasoning about what is appropriate or inappropriate to say in context. Modeling work by \cite{HellerParisienStevenson16_ProbabilisticWeighing} (see also \cite{MozuraitisEtAl18_ProductionCombination}) has argued that speakers and listeners are probabilistically weighting their own egocentric visual perspective along with their partner's perspective. An open question raised by these studies is how that weighting parameter is determined in a given context. Our results suggest that Gricean reasoning may play an important role. 

%These reasons stem from more sophisticated pragmatic expectations than simple consideration of perspective, thereby opening a deeper avenue by which theory of mind use guides flexible communication. 
% if speakers could be expected to naturally provide expressions which apply better to the target, then this behavior would be appropriate.
% If listeners arrive at this interpretation strategy through pragmatic reasoning, then neglecting the speaker's epistemic state would be rational and also the result of theory of mind use. 

%Second, because half of the instructions were unscripted, we were able to observe natural production of referential descriptions for a number of fillers. Informally, we noted a tendency toward over-informativity. Instead of ``move the stuffed animal down'', they'll say ``move the stuffed pa'nda bear down.'' Or, instead of saying ``move the plane to the right,'' they'll say ``move the red airplane to the right,'' even though there is only one plane. This suggested that the confederate's scripted instructions were in some sense uncooperative and counter to the matcher's expectations. Perhaps directors were taking the time to make more costly over-informative descriptions because they believed it was contextually relevant: both parties know that there are hidden objects in the environment. If the matcher reasoned in this way and expected the director to be overinformative, then they would be justified in picking the first object that meets the description rather than worrying about occluded cells. We tested this prediction in Exp.~2, where we removed the scripted instructions and allowed speakers to refer to items however they wished. If speakers really are being overinformative, and listeners are correctly expecting this, we should see fewer errors after removing uncooperative scripts.


%We found that speakers did naturally produce more precise, informative utterances than required and these unconstrained utterances fit the target significantly better than they fit the hidden distractor. 
%For example, no speaker in Expt.~2 produced ``the bottom block,'' which was used as a critical instruction in Expt.~1. Instead, they said ``the bluish block with a B'' or ``block with the blue writing,'' which relied on less confusable perceptual features and thereby decreased error rates. 
%Thus, the errors observed in Expt.~1 can be explained as a result of an uncooperative confederate (speaker)---the experiment set up certain pragmatic expectations through the task context, then deliberately flouted them in critical trials. 

%%%%%%%
% Discussion points: 


% 2. Other reasons for over-informativity (e.g. Judith stuff)
%%%%%%%

%The Gricean maxim of quality dictates that cooperative speakers should make their utterance as informative as is required for current purposes, but no more so. If the referring expressions used in by confederates uniquely pick out the target from the speaker's perspective, then why our unscripted speakers be more informative than this? 
%strictly necessary and why would listeners come to expect such ``overinformativity''? 
%One possibility, which we tested in Exp. 2, is that awareness of the complex mismatch in epistemic state with the listener leads the speaker to provide extra information in an attempt to avoid miscommunication.
Finally, while we are not often in communication scenarios with such explicitly marked occluders, we are near constantly in a state of uncertainty over what is in our partner's visual context. The occlusion-sensitivity we observed in Exp. 2 is representative of how pragmatic mechanisms help solve this problem.
Studies of over-informativity in referring expressions have uncovered a general tendency of speakers to provide redundant information.
This tendency can depend on a number of situational factors, such as the tendency to mention perceptually salient features to speed up the identification process  \cite{KoolenGattGoudbeekKrahmer11_Overspecification}. 
%In the current task, it seems particularly relevant that both participants knew about the presence of hidden objects, increasing uncertainty about possible distractors and placing additional pressure on the speaker to overspecify. 
The exact origin of this behavior is a subject that must be followed up by future research \cite[e.g.]{GannBarr14_AudienceDesign}, but it is clear that the tendency of speakers to produce highly informative referring expressions is useful to, and relied on by, listeners. 
%Indeed, the remaining errors in Expt.~2 are at least partially due to the lack of availability of more specific expressions. 
%The items on which errors were most likely in Expt.~2 were difficult precisely because the natural utterance was \emph{still} ambiguous: even if the speaker uses ``hairbrush'' instead of the basic-level ``brush,'' for example, the distractor remains a more typical exemplar of the subcategory.

%Further work in a wider variety of tasks is necessary to pin down the various factors determining the relative weighting of these different sources of information, but we have argued that pragmatics play a crucial role.

%Previous theoretical advances in modeling pragmatics have typically hinged on `lifting' inference over some aspect of communication that was previously assumed to be fixed. For instance, \emph{manner implicatures} emerge from uncertainty over the true meanings of words in the lexicon \cite{BergenLevyGoodman16_LexicalUncertainty}, nonliteral constructions like \emph{hyperbole} and \emph{irony} emerge from uncertainty over the topic of discussion \cite{KaoWuBergenGoodman14_NonliteralNumberWords}, and \emph{prosody} and \emph{ellipsis} emerge from uncertainty (in the form of a noisy-channel model) over the various ways that a speaker's utterance could have been corrupted  \cite{BergenGoodman15_StrategicUseOfNoise}. Note that these are not ad hoc extensions; sources of uncertainty that are not strictly necessary to explain a particular effect are often omitted for simplicity, but they all coexist within the same model. 

% While We expect our conversation partners to follow common conventions about the meanings of words \cite{Lewis69_Convention, CentolaBaronchelli15_ConventionEmergence}, to update these conventions in light of previous interactions \cite{BrennanClark96_ConceptualPactsConversation}, and perhaps most importantly, 

%It is worth noting several significant differences between our study and \cite{KeysarLinBarr03_LimitsOnTheoryOfMindUse}.
%The primary difference between our study and the original, of course, is that it was run on the web with participants connected through a virtual environment, instead of face-to-face in a room. We believe we addressed the major concern about exploring theory of mind in web experiments -- that participants do not truly believe they are interacting with another human -- by allowing instantaneous, responsive, real-time interaction.  On the other hand, it is known that textual communication, as in our chat box, can differ from face-to-face verbal communication. Additionally, we omitted the procedural step of placing the hidden distractor in a paper bag, and some aspects of the interface such as the graphical representation of occluded cells may be less intuitive, or require more training, on the web than in the lab. % Directors watched objects move through the actual moment-by-moment mouse trajectories that matchers used to drag them, and matchers saw the actual timing of the messages sent by the director.

%Finally, a key aspect of our approach was our decision not to use a confederate. While confederates are useful for reducing variation across instances of the experiment and delivering carefully targeted manipulations, their use may have unexpected consequences. Beyond the difficulties of conducting large-scale experiments with confederates, it is difficult to exactly replicate all the subtleties of the confederate's behavior that might influence results. The pair of experiments we report is a reminder that manipulations administered by a trained confederate can interact in unexpected ways with a participant's social and communicative expectations. 

\todo[inline]{End with something punchy?}

%\todo[inline]{Mention neural coordination papers? e.g. Stephens et al 2010, Stolk et al, 2014?}

%
%\section{Sample Section}
%Text here. Text here. Text here. Text here.
%Text here. Text here. Text here. Text here.
%Text here. Text here. Text here. Text here.
%Text here. Text here. Text here. Text here.
%
%\subsection{Sample Subsection}
%Text here. Text here. Text here. Text here.
%Text here. Text here. Text here. Text here.
%Text here. Text here. Text here. Text here.
%Text here. Text here. Text here. Text here.
%
%\subsubsection{Sample Subsubsection}
%Text here. Text here. Text here. Text here.
%Text here. Text here. Text here. Text here.
%Text here. Text here. Text here. Text here.
%Text here. Text here. Text here. Text here.
%
%\section{Sample equations}
%\begin{equation}
%\label{eq:rhoCHT}
%\rho^{\pi}= \frac{RI + \mathbb{E}_{\pi([L,\tau_L]|\textrm{post})}
%\left[C_L(\taupav+\tau_L) \right]   +
%\displaystyle{\int_{0}^{P}}{dw~ \mathbb{E}_{\pi_{w_L}}}
%\Biggl[\/\sum_{n_{L|[\textrm{pre},w]}}C_L(\tau_L)
%\Biggr]            }      {P +
%\mathbb{E}_{\pi([L,\tau_L] |\textrm{post})}[\tau_{L}] +\taupav +
%\displaystyle{ \int_{0}^{P}}{dw~ \mathbb{E}_{\pi_{w_L}}}   
%\Biggl[\sum_{n_{L|[\textrm{pre},w]}}\tau_L\Biggr]  
%}
%\end{equation}
%As long as
%$RI - K_LP > 
%\frac{1}{\beta}$
%\begin{equation}
%%\def\theequation{5.1}
%\left.\begin{array}{lrcl}
%&\rho^{\pi} &=&  \displaystyle\frac{\beta ( RI + K_L \taupav )-1} {\beta
%(P+\taupav )}    \\[12pt]
%\hbox{and}\hbox to .25in{\hfill}&\mathbb{E}[\tau_L | \text{post}] &=&\displaystyle \frac{P+\taupav}{\beta ( RI -
%K_LP)-1}  
%\label{eq:analytical_linear}
%\end{array}\right\}\hbox to 1.25in{\hfill}
%\end{equation} 
%
%\subsection{Simple code sample}
%
%\begin{code}
%\begin{verbatim}
%procedure bubbleSort( A : list of sortable items )
%    n = length(A)
%    repeat
%       newn = 0
%       for i = 1 to n-1 inclusive do
%          if A[i-1] > A[i] then
%             swap(A[i-1], A[i])
%             newn = i
%          end if
%       end for
%       n = newn
%    until n = 0
%end procedure
%\end{verbatim}
%\end{code}
%
%
%
%\subsection{Algorithm environment}
%
%%% \begin{algorithm} takes option [p][b][t][h],  or some combination, like \begin{figure}
%%% See documentation for algorithmic.sty for more information on formatting algorithms.
%
%\begin{algorithm}[h]
%\caption{A sample in an algorithm environment.}
%\begin{algorithmic}
%\If {$i\geq maxval$}
%    \State $i\gets 0$
%\Else
%    \If {$i+k\leq maxval$}
%        \State $i\gets i+k$
%    \EndIf
%\EndIf
%\end{algorithmic}
%\end{algorithm}
%
%
%\section{Jargon definitions}
%
%\begin{wideboxedtext}
%\begin{glossary}
%\symbol{Term} Definition
%\symbol{Term} Definition
%%ie
%%\symbol{$1/\lambda$} mean of exponential effective prior probability density for leisure time
%%\symbol{CHT} Cumulative Handling Time 
%\end{glossary}
%\end{wideboxedtext}
%
%\begin{boxedtext}
%\begin{glossary}
%\symbol{Term} Definition
%\symbol{Term} Definition
%%ie
%%\symbol{$1/\lambda$} mean of exponential effective prior probability density for leisure time
%%\symbol{CHT} Cumulative Handling Time 
%\end{glossary}
%\end{boxedtext}
%
%\section{Itemized Lists}
%
%\subsection{Roman list:}
%
%\begin{enumerate}
%\item[(i)] at high 
%payoffs, subjects work almost continuously, engaging in little leisure
%in between work bouts; 
%\item[(ii)] at low payoffs, they 
%engage in leisure all at once, in long bouts after working, rather
%than distributing the same amount of leisure time into multiple short
%leisure bouts; 
%\item[(iii)] subjects work continuously for the entire price duration, as long as
%the price is not very long (as shown by an analysis conducted by Y-AB, to be published separately); %(\textbf{Figure \ref{fig:task_data}D}).
%\item[(iv)] the duration of leisure bouts is variable.
%\end{enumerate}
%
%\subsection{Numbered list:}
%
%\begin{enumerate}
%\item at high 
%payoffs, subjects work almost continuously, engaging in little leisure
%inbetween work bouts; 
%\item at low payoffs, they 
%engage in leisure all at once, in long bouts after working, rather
%than distributing the same amount of leisure time into multiple short
%leisure bouts; 
%\item subjects work continuously for the entire price duration, as long as
%the price is not very long (as shown by an analysis conducted by Y-AB, to be published separately); %(\textbf{Figure \ref{fig:task_data}D}).
%\item the duration of leisure bouts is variable.
%\end{enumerate}
%
%
%\subsection{Bulleted list:}
%
%\begin{itemize}
%\item at high 
%payoffs, subjects work almost continuously, engaging in little leisure
%inbetween work bouts; 
%\item at low payoffs, they 
%engage in leisure all at once, in long bouts after working, rather
%than distributing the same amount of leisure time into multiple short
%leisure bouts; 
%\item subjects work continuously for the entire price duration, as long as
%the price is not very long (as shown by an analysis conducted by Y-AB, to be published separately); %(\textbf{Figure \ref{fig:task_data}D}).
%\item the duration of leisure bouts is variable.
%\end{itemize}
%
%
%\section{Sample citations}
%For general information on the correct form for citations using
%the APA 6 format, see the following sites:
%\href{https://owl.english.purdue.edu/owl/resource/560/02/}
%{APA 6, In-text citations, The Basics} and
%\href{https://owl.english.purdue.edu/owl/resource/560/03/}
%{APA 6, In-text citations}
%
%\section{Natbib citation mark up}
%
%\subsection{Single citations}
%\noindent
%\begin{tabular}{ll}
%\bf Type&\bf Results\\
%\hline
%\verb+\citet{jon90}+&Jones et al. (1990)\\
%\verb+\citet[chap. 2]{jon90}+&Jones et al. (1990, chap. 2)\\
%    \verb+\citep{jon90}+	    &   	(Jones et al., 1990)\\
%    \verb+\citep[chap. 2]{jon90}+ 	&    	(Jones et al., 1990, chap. 2)\\
%    \verb+\citep[see][]{jon90}+ 	 &    	(see Jones et al., 1990)\\
%    \verb+\citep[see][chap. 2]{jon90}+ 	&    	(see Jones et al., 1990, chap. 2)\\
%    \verb+\citet*{jon90}+ 	    &    	Jones, Baker, and Williams (1990)\\
%    \verb+\citep*{jon90}+	    &    	(Jones, Baker, and Williams,
%    1990) \\
%\end{tabular}
%
%For example, some citations from the OpenMindSample bibliography:
%citet:\citet{anderson}, citep:\citep{antibayes}, and
%cite*: \citet*{anderson}.
%
%\subsection{Multiple citations}
%Multiple citations may be made by including more than one citation
%key in the \verb+\cite+ command argument.
%
%\noindent
%\begin{tabular}{ll}
%\bf Type&\bf Results\\
%\hline
%\verb+\citet{jon90,jam91}+&Jones et al. (1990); James et al. (1991)\\
%\verb+\citep{jon90,jam91}+&(Jones et al., 1990; James et al. 1991)\\
%\verb+\citep{jon90,jon91}+&(Jones et al., 1990, 1991)\\
%\verb+\citep{jon90a,jon90b}+&(Jones et al., 1990a,b)\\
%\end{tabular}
%
%For example, multiple citations from the OpenMindSample bibliography:
%citet:\citet{anderson,antibayes}, citep:\citep{anderson,antibayes}.
%As you see, the citations are automatically hyperlinked to their
%reference in the bibliography.
%
%\newpage
%
%\section{Sample figures}
%
%\begin{figure}[h] 
%\centerline{\includegraphics[width=\textwidth]{Fig1}}
%\caption{(Colour online) \textbf{Task and key features of the
% data.} \\
% A) Cumulative handling time (CHT) task. Grey bars denote work
%(depressing a lever), white gaps show leisure. The subject must
% accumulate work up to a total period of time called the
%\emph{price} ($P$) in order to obtain a single reward (black dot) of subjective reward
%intensity $RI$. The trial duration is $25\times \mathrm{price}$ (plus
%$2$s each time the price is attained, during which the lever is retracted so it cannot
%work; not shown).
%}
%\label{fig:task_data}
%\end{figure}
%
%\begin{figure}[ht] 
%\widefigure{\fullpagewidth}{Fig1}
%\caption{(Colour online) \textbf{Task and key features of the
% data.} \\
%A) Cumulative handling time (CHT) task. Grey bars denote work
%(depressing a lever), white gaps show leisure. The subject must
%accumulate work up to a total period of time called the
%\emph{price} ($P$) in order to obtain a single reward (black dot) of subjective reward
%intensity $RI$. The trial duration is $25\times \mathrm{price}$ (plus
%$2$s each time the price is attained, during which the lever is retracted so it cannot
%work; not shown).
%}
%\label{newfig:task_data}
%\end{figure}
%
%\clearpage
%\section{Sample tables}
%
%\begin{table}[!ht]
%\caption{Time of the Transition Between Phase 1 and Phase 2$^{a}$}
%\label{tab:label}
%\centering
%\begin{tabular}{lc}
%\hline
% Run  & Time (min)  \\
%\hline
%  $l1$  & 260   \\
%  $l2$  & 300   \\
%  $l3$  & 340   \\
%  $h1$  & 270   \\
%  $h2$  & 250   \\
%  $h3$  & 380   \\
%  $r1$  & 370   \\
%  $r2$  & 390   \\
%\hline
%\multicolumn{2}{l}{$^{a}$Table note text here.}
%\end{tabular}
%\end{table}
%
%\begin{table}[ht]
%\widecaption{Sample table taken from [treu03]\label{tbl-1}}
%\begin{widetable}
%\advance\tabcolsep-1pt
%\small
%\begin{tabular}{ccrrccccccccc}
%\hline
%\bf 
%POS &\bf  chip &\multicolumn1c{\bf ID} &\multicolumn1c{\bf X}
%&\multicolumn1c{\bf Y} &\bf
%RA &\bf DEC &\bf IAU$\pm$ $\delta$ IAU &\bf
%IAP1$\pm$ $\delta$ IAP1 &\bf IAP2 $\pm$ $\delta$
%IAP2 &\bf star &\bf E &\bf Comment\\
%\hline
%0 & 2 & 1 & 1370.99 & 57.35\rlap{$^a$}    &   6.651120 &  17.131149 &
%21.344$\pm$0.006\rlap{$^b$}  & 2 4.385$\pm$0.016 & 23.528$\pm$0.013 & 0.0 & 9 & -    \\
%0 & 2 & 2 & 1476.62 & 8.03     &   6.651480 &  17.129572 & 21.641$\pm$0.005  & 2 3.141$\pm$0.007 & 22.007$\pm$0.004 & 0.0 & 9 & -    \\
%0 & 2 & 3 & 1079.62 & 28.92    &   6.652430 &  17.135000 & 23.953$\pm$0.030  & 2 4.890$\pm$0.023 & 24.240$\pm$0.023 & 0.0 & - & -    \\
%0 & 2 & 4 & 114.58  & 21.22    &   6.655560 &  17.148020 & 23.801$\pm$0.025  & 2 5.039$\pm$0.026 & 24.112$\pm$0.021 & 0.0 & - & -    \\
%0 & 2 & 5 & 46.78   & 19.46    &   6.655800 &  17.148932 & 23.012$\pm$0.012  & 2 3.924$\pm$0.012 & 23.282$\pm$0.011 & 0.0 & - & -    \\
%0 & 2 & 6 & 1441.84 & 16.16    &   6.651480 &  17.130072 & 24.393$\pm$0.045  & 2 6.099$\pm$0.062 & 25.119$\pm$0.049 & 0.0 & - & -    \\
%0 & 2 & 7 & 205.43  & 3.96     &   6.655520 &  17.146742 & 24.424$\pm$0.032  & 2 5.028$\pm$0.025 & 24.597$\pm$0.027 & 0.0 & - & -    \\
%0 & 2 & 8 & 1321.63 & 9.76     &   6.651950 &  17.131672 &
%22.189$\pm$0.011  & 2 4.743$\pm$0.021 & 23.298$\pm$0.011 & 0.0 & 4 &
%edge \\
%\hline
%\multicolumn{13}{l}{%
%Table 2 is published in its entirety in the electronic
%edition of the {\it Astrophysical Journal}.}\\[3pt]
%\multicolumn{13}{l}{%
%$^a$ Sample footnote for table 2.}\\[3pt]
%\multicolumn{13}{l}{%
%$^b$ Another sample footnote for table 2.}
%\end{tabular}
%\end{widetable}
%\end{table}
%
%\begin{table}[p]
%\rotatebox{90}{\vbox{\hsize=\textheight
%\caption{Here is a caption for a table that is found in landscape
%mode.}
%\begin{tabular}{ccrrccccccccc}
%\hline
%\bf 
%POS &\bf  chip &\multicolumn1c{\bf ID} &\multicolumn1c{\bf X}
%&\multicolumn1c{\bf Y} &\bf
%RA &\bf DEC &\bf IAU$\pm$ $\delta$ IAU &\bf
%IAP1$\pm$ $\delta$ IAP1 &\bf IAP2 $\pm$ $\delta$
%IAP2 &\bf star &\bf E &\bf Comment\\
%\hline
%0 & 2 & 1 & 1370.99 & 57.35\rlap{$^a$}    &   6.651120 &  17.131149 &
%21.344$\pm$0.006\rlap{$^b$}  & 2 4.385$\pm$0.016 & 23.528$\pm$0.013 & 0.0 & 9 & -    \\
%0 & 2 & 2 & 1476.62 & 8.03     &   6.651480 &  17.129572 & 21.641$\pm$0.005  & 2 3.141$\pm$0.007 & 22.007$\pm$0.004 & 0.0 & 9 & -    \\
%0 & 2 & 3 & 1079.62 & 28.92    &   6.652430 &  17.135000 & 23.953$\pm$0.030  & 2 4.890$\pm$0.023 & 24.240$\pm$0.023 & 0.0 & - & -    \\
%0 & 2 & 4 & 114.58  & 21.22    &   6.655560 &  17.148020 & 23.801$\pm$0.025  & 2 5.039$\pm$0.026 & 24.112$\pm$0.021 & 0.0 & - & -    \\
%0 & 2 & 5 & 46.78   & 19.46    &   6.655800 &  17.148932 & 23.012$\pm$0.012  & 2 3.924$\pm$0.012 & 23.282$\pm$0.011 & 0.0 & - & -    \\
%0 & 2 & 6 & 1441.84 & 16.16    &   6.651480 &  17.130072 & 24.393$\pm$0.045  & 2 6.099$\pm$0.062 & 25.119$\pm$0.049 & 0.0 & - & -    \\
%0 & 2 & 7 & 205.43  & 3.96     &   6.655520 &  17.146742 & 24.424$\pm$0.032  & 2 5.028$\pm$0.025 & 24.597$\pm$0.027 & 0.0 & - & -    \\
%0 & 2 & 8 & 1321.63 & 9.76     &   6.651950 &  17.131672 &
%22.189$\pm$0.011  & 2 4.743$\pm$0.021 & 23.298$\pm$0.011 & 0.0 & 4 &
%edge \\
%\hline
%\multicolumn{13}{l}{%
%Table 2 is published in its entirety in the electronic
%edition of the {\it Astrophysical Journal}.}\\[3pt]
%\multicolumn{13}{l}{%
%$^a$ Sample footnote for table 2.}\\[3pt]
%\multicolumn{13}{l}{%
%$^b$ Another sample footnote for table 2.}
%\end{tabular}
%}}
%\end{table}
%\clearpage
%
%
%\vglue 3in
%Example of table continuing over pages:
%
%
%\begin{center}
%\begin{longtable}{ccc@{}}
%\caption{ApJ costs from 1991 to 2013
%\label{tab:table}} \\[2pt]
%\hline
%\bf Year & \bf Subscription & \bf Publication \\
% & \bf cost &\bf charges\\
% & \bf(\$) & \bf (\$/page)\\
%\hline
%\endfirsthead
%
%\multicolumn3c{Table \thetable, \it continued from previous page.}\\[6pt]
%\multicolumn3c{ApJ costs from 1991 to 2013}\\[2pt]
%\hline
%\bf Year & \bf Subscription & \bf Publication \\
% & \bf cost &\bf charges\\
% & \bf(\$) & \bf (\$/page)\\
%\hline
%\endhead
%\\\hline
%\\[-8pt]
%\multicolumn{3}{r}{\it Table continued on next page}\\ 
%\endfoot
%
%\hline
%\endlastfoot
%
%1991 & 600 & 100 \\
%1992 & 650 & 105 \\
%1993 & 550 & 103 \\
%1994 & 450 & 110 \\
%1995 & 410 & 112 \\
%1996 & 400 & 114 \\
%1997 & 525 & 115 \\
%1998 & 590 & 116 \\
%1999 & 575 & 115 \\
%2000 & 450 & 103 \\
%2001 & 490 &  90 \\
%2002 & 500 &  88 \\
%2003 & 450 &  90 \\
%2004 & 460 &  88 \\
%2005 & 440 &  79 \\
%2006 & 350 &  77 \\
%2007 & 325 &  70 \\
%2008 & 320 &  65 \\
%2009 & 190 &  68 \\
%2010 & 280 &  70 \\
%2011 & 275 &  68 \\
%2012 & 150 &  56 \\
%2013 & 140 &  55 \\
%\end{longtable}
%\end{center}

\section{Supportive Information}
Here you enter further sources of information, if desired.

%% A possible entry might be:
% No supportive information is available at this time.


\acknowledgments
Enter your acknowledgments here.

%% ie.,

% The authors thank Laurence Aitchison for fruitful discussions.  RKN
% and PD received funding from the Gatsby Charitable Foundation. Y-AB,
% RBS, KC and PS received funding from Canadian Institutes of Health
% Research grant $MOP74577$,
% Fond de recherche Qu\'{e}bec - Sant\'{e} (Group grant to the Groupe 
% de recherche en neurobiologie comportementale, Shimon Amir, P.I.), and
% Concordia University Research Chair (Tier I). 

\authorcontributions 
Who helped formulate the project, who supplied data, analyses and
experiments, etc.

%% ie.
%% Project was formulated by RKN, PD, PS,
%% based on substantial data, analyses and experiments of Y-AB, KC, RS,
%% PS. RKN, PD formalised the model, RKN implemented and ran the model;
%% RKN analysed the molecular ethogram data; Y-AB formalised and
%% implemented a CTMC model. All authors wrote the manuscript.


%%%%%%%%%%%%%%%%%%%%%%%
%% The bibliography

%% \nocite{*} is used here as a quick way to get every entry  in the .bib file to
%% appear in the bibliography. Normally the bibliography is made using only
%% the bibentries that you cite using \cite{}, or one of the Natbib citation
%% entries, like \citep{}, \citet{} etc.

%\nocite{*}
\bibliography{refs}


%\appendix

%\section{Sample Appendix Section}
%We derive the result in Eq. \eqref{eq:analytical_linear}. We consider a linear $C_L(\tau_L+\taupav)=K_L(\tau_L+\taupav)$, and
%make two further 
%simplifications: (i) the subject does not
%engage in leisure in the pre-reward state (and so works for the whole
%price when it works); and (ii) \emph{a priori}, arbitrarily long leisure durations are possible
%($\lambda=0$).
%Then the reward rate in Eq. \eqref{eq:rhoCHT} becomes
%\begin{equation}\label{eq:analyticalrho}
%\rho^{\pi}= \frac{\vrule height 10pt width0pt RI + K_L \{~ \mathbb{E}[ \tau_L | \textrm{post} ] + \taupav  \} }
%     {P +
%\mathbb{E}[ \tau_L | \textrm{post} ] +\taupav  } 
%\end{equation} 
%As discussed in the \emph{Results} section, the probability of engaging in instrumental leisure in the post-reward state is $\pi([L,\tau_L]
%~| \textrm{post}) = \exp\left[-\{\beta (\rho^\pi-K_L) 
% \} \tau_L\right]$, which is an exponential distribution with
%mean 
%\begin{equation}
%\mathbb{E}[\tau_L | \textrm{post}]=\frac{1}{\beta (\rho^\pi-K_L) }
%\label{eq:analyticaltauL}
%\end{equation}  
%Re-arranging terms of this equation,
%\begin{equation}\label{eq:rhoversion2}
%\rho^{\pi}=\frac{1}{\beta ~\mathbb{E}[\tau_L | \textrm{post}]} +K_L 
%\end{equation} 
%Equating Eqs. \eqref{eq:analyticalrho} and \eqref{eq:rhoversion2} and solving for the mean instrumental leisure duration $\mathbb{E}[\tau_L | \textrm{post}]$, we derive
%\begin{equation}
%\mathbb{E}[\tau_L | \textrm{post}] = \frac{P+\taupav}{\beta ( RI - K_LP)-1} 
%\label{eq:solvedtauL}
%\end{equation}
%which is the second line of Eq.\eqref{eq:analytical_linear}. This is the mean instrumental leisure duration as long as  $RI - K_LP>1$, and  $\mathbb{E}[\tau_L | \textrm{post}] \rightarrow \infty$ otherwise. When the former condition holds, we may
%substitute Eq. \eqref{eq:solvedtauL} into Eq. \eqref{eq:analyticalrho} and solve for $\rho^{\pi}$
%
%\begin{figure}
%\widefigure{\fullpagewidth}{Fig1}
%\caption{Sample Appendix Caption. Here is a caption that might
%appear in an appendix. It is as wide as the full width of the page.}
%\end{figure}

%\newpage

%\section{Making Your Bibliography for an Open Mind Article}
%{\it Open Mind} uses the APA author-date  bibliography style,
%apacite.bst. For more
%information on apacite, for examples in how to make your .bib file and more, see:\\
%\href{http://mirror.jmu.edu/pub/CTAN/biblio/bibtex/contrib/apacite/apacite.pdf}
%{http://mirror.jmu.edu/pub/CTAN/biblio/bibtex/contrib/apacite/apacite.pdf}
%
%\noindent
%(In spite of the mention of apacite cite commands, please use only
%Natbib commands for in text citations, as shown above.)
%
%\subsection{BibTeX}
%You will need to use BibTeX to form your bibliography; typing in the
%references would be
%a huge and unpleasant task. Look at the openmindsample.bbl file and you'll see why
%typing in the bibitems would be difficult. 
%
%For a good basic introduction to using BibTeX, see
%\href{https://www.economics.utoronto.ca/osborne/latex/BIBTEX.HTM}
%{https://www.economics.utoronto.ca/osborne/latex/BIBTEX.HTM}
%
%When you use BibTeX, the form of the bibliography will be correct. You
%don't need to supply a bibliography style, since that is built into
%the stjour.cls file.

\end{document}

