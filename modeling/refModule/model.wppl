var speakerModel = function(target, context, params) {

  // Cost of utterance
  var uttCost = function(utt) {
    return utt.split('').length;
  };

  // Looks up meaning in given lexicon (if exists, use inf; otherwise nuke it)
  var meaning = function(utt, object) {
    var lexicalEntry = params.lexicon[utt];
    return _.has(lexicalEntry, object) ? lexicalEntry[object] : -Infinity; 
  };
  
  // Egocentric listener who selects among objects in context using lexicon
  var L0 = cache(function(utt, perceivedContext){
    return Infer({method:'enumerate', model: function(){
      var object = uniformDraw(perceivedContext);
      factor(params.typWeight * meaning(utt,object)); 
      return object;
    }});
  });

  // Egocentric speaker who simply trades off pure informativeness in lexicon
  // and cost of utterance
  var S0 = cache(function(target, context) {
    var utts = refModule.possibleUtts(target, params.lexicon);
    return Infer({method:'enumerate', model: function(){
      var utt = uniformDraw(utts);
      var utility = ((1-params.costWeight) * meaning(utt, target)
		     - params.costWeight * uttCost(utt));
      factor(params.alpha * utility);
      return utt;
    }});
  });
  
  // should probably insert a few different options here...
  // e.g. 'paranoid' -- which imagines a bunch of very similar objects to target
  //      'omniscient' -- where you see the actual object
  //      'hierarchical' -- where you assume contexts are drawn from distribution
  var marginalizeListener = function(utt, object, context) {
    return Infer({method: 'enumerate', model: function() {
      var omniscient = flip(params.omniscienceProb);
      var lview = omniscient ? context.shared.concat(context.occluded) : context.shared;
      return sample(L0(utt, lview));
    }});
  };
  
  // Selects among utterances given *informativity in context* and cost of production,
  // possibly marginalizing over possible noise in perception of context
  var S1 = function(target, context) {
    var utts = refModule.possibleUtts(target, params.lexicon);
    return Infer({method:'enumerate', model: function(){
      var utt = uniformDraw(utts);
      var listener = marginalizeListener(utt, target, context);
      var utility = ((1-params.costWeight) * listener.score(target)
		     - params.costWeight * uttCost(utt));
      factor(params.alpha * utility);
      return utt;
    }});
  };

  var weightedSpeaker = function(target, context) {
    return Infer({method:'enumerate', model: function(){
      var speakerModel = flip(params.perspectiveWeight) ? S0 : S1;
      return sample(speakerModel(target,context));
    }});
  };
  
  // Listener only considers objects speaker can see (model Keysar is arguing against)
  var L2 = cache(function(utt, perceivedContext) {
    var fullObjSet = perceivedContext.shared.concat(perceivedContext.occluded);
    return Infer({method: 'enumerate'}, function() {
      var object = uniformDraw(perceivedContext.shared);    
      var speakerContext = perceivedContext.shared;
      observe(S1(object, speakerContext), utt);
      return object.color + " " + object.type;
    });
  });


  return (params.model == 'egocentric' ? S0(target, context) :
	  params.model == 'weighted' ? weightedSpeaker(target, context) :
	  params.model == 'visualAccess' || params.model == 'uncertainRSA' ? S1(target, context) :
	  console.error('unknown model: ' + params.model));
};
